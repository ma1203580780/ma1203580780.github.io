<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>MARTIST</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://martist.cn/"/>
  <updated>2019-01-04T10:22:33.145Z</updated>
  <id>http://martist.cn/</id>
  
  <author>
    <name>马闯</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分销海报的生成</title>
    <link href="http://martist.cn/2019/01/04/PHP/%E5%88%86%E9%94%80%E6%B5%B7%E6%8A%A5%E7%9A%84%E7%94%9F%E6%88%90/"/>
    <id>http://martist.cn/2019/01/04/PHP/分销海报的生成/</id>
    <published>2019-01-03T16:00:00.000Z</published>
    <updated>2019-01-04T10:22:33.145Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="产品需求"><a href="#产品需求" class="headerlink" title="产品需求"></a>产品需求</h2><p>最近流行用朋友圈海报图进行拉新或者一些运营活动，这个海报生成需要有一些用户的个人信息数据，怎么做到很快生成海报返回用户，并且保证清晰度呢？</p><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>1.PHP的gd库，通过添加水印的方式生成海报，保存海报图到服务器，然后发给用户图片地址（服务端生成，准确率高，缺点就是慢）<br>2.js的canvas特性生成（客户端生成，速度快，缺点是不稳定，不同机型不一定都能成图）</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>不啰嗦了，核心代码如下</p><pre><code>&lt;div id=&quot;content&quot; &gt;    &lt;img width=&quot;100%&quot; src=&quot;&lt;{$background_img_url}&gt;&quot; alt=&quot;&quot;&gt;    &lt;p id=&quot;service_erweima&quot; class=&quot;code&quot; crossOrigin=&quot;Anonymous&quot;&gt;&lt;/p&gt;    &lt;span class=&quot;mess&quot;&gt;扫码免费领课和我一起学习&lt;/span&gt;    &lt;img src=&quot;&lt;{$head_img}&gt;&quot; alt=&quot;&quot; class=&quot;user&quot; crossOrigin=&quot;Anonymous&quot;&gt;    &lt;span class=&quot;name&quot;&gt;&lt;{$user_name}&gt;&lt;/span&gt;    &lt;input type=&quot;hidden&quot; id=&quot;m_redirect_code&quot; value=&quot;&lt;{$m_redirect_code}&gt;&quot;&gt;    &lt;input type=&quot;hidden&quot; id=&quot;code&quot; value=&quot;&lt;{$code}&gt;&quot;&gt;&lt;/div&gt;&lt;script src=&quot;https://cdn.bootcss.com/jquery/3.3.1/jquery.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.bootcss.com/html2canvas/0.5.0-beta4/html2canvas.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/Public/Js/qrcode.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;    sleep(1000);//生成二维码    new QRCode(document.getElementById(&quot;service_erweima&quot;), {        text: ’https://www.your_host_url.com‘,        width: 100,        height: 100,        border:1,        colorDark : &apos;#000000&apos;, //前景色        colorLight : &apos;#ffffff&apos;  //背景色    });//canvas生成海报    html2canvas($(&apos;#content&apos;),{        useCORS: true,        logging: false,        onrendered: function(canvas) {            var image = new Image();            image.crossOrigin = &apos;anonymous&apos;;            image.src = canvas.toDataURL(&quot;image/png&quot;);            $(&apos;#public-content&apos;).append(image);            $(&apos;#content&apos;).hide();        }    });//需要等待图片完全加载完了，DOM渲染完了，再生成，所以等一等    function sleep(delay) {        var start = (new Date()).getTime();        while ((new Date()).getTime() - start &lt; delay) {            continue;        }    }&lt;/script&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu下开启mysql的bin_log日志</title>
    <link href="http://martist.cn/2018/10/12/MYSQL/Ubuntu%E4%B8%8B%E5%BC%80%E5%90%AFmysql%E7%9A%84bin_log%E6%97%A5%E5%BF%97/"/>
    <id>http://martist.cn/2018/10/12/MYSQL/Ubuntu下开启mysql的bin_log日志/</id>
    <published>2018-10-11T16:00:00.000Z</published>
    <updated>2018-11-01T03:21:56.353Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="mysqlbinlog工具"><a href="#mysqlbinlog工具" class="headerlink" title="mysqlbinlog工具"></a>mysqlbinlog工具</h2><p>mysqlbinlog是一个客户端程序，可以审查binlog文件及中继日志文件的内容。既可以读取本地也可以读取远程的binlog文件，输出二进制日志的内容。</p><p>mysqlbinlog常用的选项：</p><pre><code>—database=db_name，-d db_name</code></pre><p>只列出该数据库的条目(只用本地日志)。</p><pre><code>–force-read，-f</code></pre><p>使用该选项，如果mysqlbinlog读它不能识别的二进制日志事件，它会打印警告，忽略该事件并继续。没有该选项，如果mysqlbinlog读到此类事件则停止。</p><pre><code>–read-from-remote-server，-R</code></pre><p>从MySQL服务器读二进制日志。如果未给出该选项，任何连接参数选项将被忽略。这些选项是–host、–password、–port、–protocol、–socket和–user。</p><pre><code>–host=host_name，-h host_name</code></pre><p>获取给定主机上的MySQL服务器的二进制日志。</p><pre><code>–port=port_num，-P port_num</code></pre><p>用于连接远程服务器的TCP/IP端口号。</p><pre><code>–user=user_name，-u user_name</code></pre><p>连接远程服务器时使用的MySQL用户名。</p><pre><code>–password[=password]，-p[password]</code></pre><p>当连接服务器时使用的密码。如果使用短选项形式(-p)，选项和密码之间不能有空格。如果在命令行中–password或-p选项后面没有密码值，则提示输入一个密码。</p><pre><code>–result-file=name,-r name</code></pre><p>将输出指向给定的文件。</p><pre><code>–short-form，-s</code></pre><p>只显示日志中包含的语句，不显示其它信息。</p><pre><code>–start-datetime=datetime</code></pre><p>从二进制日志中第1个日期时间等于或晚于datetime参量的事件开始读取。datetime值相对于运行mysqlbinlog的机器上的本地时区。该值格式应符合DATETIME或TIMESTAMP数据类型。例如：</p><p>shell&gt; mysqlbinlog–start-datetime=”2004-12-25 11:25:56″binlog.000003该选项可以帮助点对点恢复。</p><pre><code>–stop-datetime=datetime</code></pre><p>从二进制日志中第1个日期时间等于或晚于datetime参量的事件起停止读。关于datetime值的描述参见–start-datetime选项。该选项可以帮助及时恢复。</p><pre><code>–start-position=N</code></pre><p>从二进制日志中第1个位置等于N参量时的事件开始读。</p><pre><code>–stop-position=N</code></pre><p>从二进制日志中第1个位置等于和大于N参量时的事件起停止读。</p><h2 id="利用mysqlbinlog-拿到你想要的原生sql"><a href="#利用mysqlbinlog-拿到你想要的原生sql" class="headerlink" title="利用mysqlbinlog 拿到你想要的原生sql"></a>利用mysqlbinlog 拿到你想要的原生sql</h2><p>执行：</p><pre><code>bin ./mysqlbinlog -v --base64-output=DECODE-ROWS  ~/Downloads/tymysql2|grep  -A4  &apos;ALTER&apos; &gt;~/Downloads/alter2.text</code></pre><p>参数：</p><pre><code>-v 是显示出一些sql的信息 -vv则是多一些注释性的东西--base64-output=DECODE-ROWS 这个是把sql解码出来~/mysql/data/mysql.bin.000001 这里是你的binlog文件grep -A4 &apos;ALTER&apos; 这个则是匹配alter语句以及后四行&gt; ~/Downloads/test.sql  则是把匹配出来的sql语句输出到指定文件</code></pre><p>参考：<br><a href="https://www.cnblogs.com/jackluo/p/3336585.html" target="_blank" rel="external">https://www.cnblogs.com/jackluo/p/3336585.html</a><br><a href="https://www.cnblogs.com/martinzhang/p/3454358.html" target="_blank" rel="external">https://www.cnblogs.com/martinzhang/p/3454358.html</a><br><a href="http://blog.51cto.com/suifu/1881116" target="_blank" rel="external">http://blog.51cto.com/suifu/1881116</a><br><a href="https://my.oschina.net/Laily/blog/648776" target="_blank" rel="external">https://my.oschina.net/Laily/blog/648776</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="laravel" scheme="http://martist.cn/categories/laravel/"/>
    
    
      <category term="laravel" scheme="http://martist.cn/tags/laravel/"/>
    
  </entry>
  
  <entry>
    <title>laravel+elastic笔记</title>
    <link href="http://martist.cn/2018/10/10/LARAVEL/laravel+elastic%E7%AC%94%E8%AE%B0/"/>
    <id>http://martist.cn/2018/10/10/LARAVEL/laravel+elastic笔记/</id>
    <published>2018-10-09T16:00:00.000Z</published>
    <updated>2018-11-01T03:21:25.343Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><p>版本很重要<br>由点及面，先实践起来再学细节的原理和使用</p><h2 id="技术栈"><a href="#技术栈" class="headerlink" title="技术栈"></a>技术栈</h2><pre><code>laravel5.5框架+scout组件+elasticsearch6.3.0搜索引擎</code></pre><h3 id="辅助"><a href="#辅助" class="headerlink" title="辅助"></a>辅助</h3><pre><code>elasticsearch-head 查看集群数据可视化中文分词插件Ik</code></pre><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>laravel是一款现代化的php框架<br>es是搜索引擎<br>es-head是管理查看使用es的图形界面工具<br>scout是laravel一款优秀的组件</p><h2 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h2><h3 id="laravel"><a href="#laravel" class="headerlink" title="laravel"></a>laravel</h3><p>laravel安装器安装：</p><pre><code>laravel new larasearch</code></pre><p>配置env文件：</p><pre><code>DB_CONNECTION=mysqlDB_HOST=127.0.0.1DB_PORT=3306DB_DATABASE=julyeduDB_USERNAME=rootDB_PASSWORD=123456</code></pre><p>这时php artisan命令启动，访问127.0.0.1:8000 就可以看到项目首页了。</p><h3 id="es"><a href="#es" class="headerlink" title="es"></a>es</h3><p>在es的官网挑选一个合适的版本，建议选择6.3.0，以便配套使用IK和ES-head。</p><pre><code># 下载https://www.elastic.co/downloads/past-releases</code></pre><h3 id="IK"><a href="#IK" class="headerlink" title="IK"></a>IK</h3><p>1.直接plugin命令安装</p><pre><code>./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip</code></pre><p>2.配置修改ik的版本适应es6.3.1,修改文件plugin-descriptor.properties，config文件夹下的配置文件主要是IK本身暂时不需要修改，这个properties文件主要是和es交互，修改其es版本和jdk版本号</p><pre><code># 修改elasticsearch-head/plugin-descriptor.properties文件description=head - A web front end for an elastic search clusterversion=6.3.1site=truename=analysis-ikclassname=org.elasticsearch.plugin.analysis.ik.AnalysisIkPluginjava.version=1.8elasticsearch.version=6.3.1 </code></pre><h3 id="es-head"><a href="#es-head" class="headerlink" title="es-head"></a>es-head</h3><p>head是基于node开发的，所以需要先安装node<br>node下载地址：<a href="http://cdn.npm.taobao.org/dis" target="_blank" rel="external">http://cdn.npm.taobao.org/dis</a>…</p><p>在电脑任意一个目录下（不要在elasticsearch目录里面），执行一下命令，</p><pre><code>git clone https://github.com/mobz/elasticsearch-head.git  cd elasticsearch-head/  npm install  </code></pre><p>为了es-head可以访问es，所以需要配置跨域：</p><p>修改两个地方：</p><pre><code>#elasticsearch-headGruntfile.jsconnect: {    server: {        options: {            port: 9100,            hostname: &apos;*&apos;,            base: &apos;.&apos;,            keepalive: true        }    }}#elasticsearch-5.6.0configelasticsearch.ymlhttp.cors.enabled: true  http.cors.allow-origin: &quot;*&quot;  </code></pre><h2 id="scout"><a href="#scout" class="headerlink" title="scout"></a>scout</h2><p>通过composer安装依赖包</p><pre><code>composer require laravel/scoutcomposer require tamayo/laravel-scout-elastic</code></pre><p>基本配置</p><p>在config/app.php文件中的providers数组中加入服务提供者</p><pre><code>// config/app.php&apos;providers&apos; =&gt; [    // ...    Laravel\Scout\ScoutServiceProvider::class,    // ...    ScoutEngines\Elasticsearch\ElasticsearchProvider::class,],</code></pre><p>使用以下命令生成scout配置文件</p><pre><code>php artisan vendor:publish --provider=&quot;Laravel\Scout\ScoutServiceProvider&quot;</code></pre><p>在config/scout.php中加入elasticsearch的配置</p><pre><code>&apos;elasticsearch&apos; =&gt; [    &apos;index&apos; =&gt; env(&apos;ELASTICSEARCH_INDEX&apos;, &apos;laravel&apos;),    &apos;hosts&apos; =&gt; [        env(&apos;ELASTICSEARCH_HOST&apos;, &apos;http://localhost:9200&apos;),    ],],</code></pre><p>然后我们打开.env文件，加入scout和elasticsearch的配置</p><pre><code># scout配置SCOUT_DRIVER=elasticsearchSCOUT_PREFIX=# elasticsearch 配置ELASTICSEARCH_INDEX=esdemo# elasticsearch 地址ELASTICSEARCH_HOST=http://172.30.6.1:9200</code></pre><h3 id="相关文档地址"><a href="#相关文档地址" class="headerlink" title="相关文档地址"></a>相关文档地址</h3><p>laravel scout中文文档地址：<a href="https://laravel-china.org/docs/laravel/5.3/scout/1205" target="_blank" rel="external">https://laravel-china.org/docs/laravel/5.3/scout/1205</a><br>es中文文档地址：<a href="https://www.elastic.co/guide/cn/elasticsearch/php/current/_configuration.html" target="_blank" rel="external">https://www.elastic.co/guide/cn/elasticsearch/php/current/_configuration.html</a><br>es6.3.0地址：<a href="https://www.elastic.co/downloads/past-releases/elasticsearch-6-3-0" target="_blank" rel="external">https://www.elastic.co/downloads/past-releases/elasticsearch-6-3-0</a><br>IK github地址：<a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="external">https://github.com/medcl/elasticsearch-analysis-ik</a></p><h2 id="启动并查看"><a href="#启动并查看" class="headerlink" title="启动并查看"></a>启动并查看</h2><p>启动es</p><pre><code>./bin/elasticsearch</code></pre><p>地址</p><pre><code>http://127.0.0.1:9200/</code></pre><p>启动es-head</p><pre><code>npm run start</code></pre><p>地址</p><pre><code>http://127.0.0.1:9100</code></pre><p>启动laravel项目</p><pre><code>php artisan serve</code></pre><p>地址</p><pre><code>http://127.0.0.1:8000/es/s?page=1</code></pre><h2 id="测试执行"><a href="#测试执行" class="headerlink" title="测试执行"></a>测试执行</h2><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><h4 id="创建模型并填充数据"><a href="#创建模型并填充数据" class="headerlink" title="创建模型并填充数据"></a>创建模型并填充数据</h4><p>创建模型app/Ques.php，为方便后续测试，请先建表和填充数据，可以手动使用sql语句添加数据，也使用laravel自动的数据迁移和填充。</p><pre><code>&lt;?phpnamespace App;use Illuminate\Database\Eloquent\Model;use Laravel\Scout\Searchable;/** * 学生模型 */class Ques extends Model{     use Searchable;    //定义关联的表名，不定义的话默认此模型关联的表为 模型名s (users)    protected $table = &apos;aws_ques_tb_0&apos;;    /******字段相关*******/    #定义主键字段名，默认是id    protected $primaryKey = &apos;id&apos;;    #定义字段白名单，允许操作表中的哪些字段    // protected $fillable = [&apos;ques&apos;,&apos;name&apos;];    #定义字段黑名单，不允许操作表中哪些字段    protected $guarded = [];    //1、使用model::create([])等方法直接对orm对象操作使，必须定义$guarded或者$fillable    //2、使用$m = new model();然后$m-&gt;save()的方式不需要定义    //3、简便的方式就是定义$fillable = [];    #定义隐藏的字段    protected $hidden = [];    /**     * 索引名称     *     * @return string     */    public function searchableAs()    {        return &apos;ques_index&apos;;    }    /**     * 索引名称     *     * @return string     */    public function searchableAs()    {        return &apos;Quess_index&apos;;    }    /**     * 可搜索的数据索引     *     * @return array     */    public function toSearchableArray()    {        $array = $this-&gt;toArray();        // Customize array...        return $array;    }}</code></pre><h4 id="把所有现有记录导入到搜索索引里"><a href="#把所有现有记录导入到搜索索引里" class="headerlink" title="把所有现有记录导入到搜索索引里"></a>把所有现有记录导入到搜索索引里</h4><pre><code>php artisan scout:import &quot;App\Ques&quot;</code></pre><h4 id="导入过程"><a href="#导入过程" class="headerlink" title="导入过程"></a>导入过程</h4><pre><code>Imported [App\Ques] models up to ID: 500Imported [App\Ques] models up to ID: 1000Imported [App\Ques] models up to ID: 1500Imported [App\Ques] models up to ID: 2000All [App\Ques] records have been imported.</code></pre><p>我们访问es，是不是已经有了刚刚导入的Quess_index索引数据。</p><pre><code>http://172.30.6.1:9200/esdemo/Ques_index/_search</code></pre><h4 id="试试搜索"><a href="#试试搜索" class="headerlink" title="试试搜索"></a>试试搜索</h4><p>在route/web.php中写个demo，试试看；</p><pre><code>Route::get(&apos;/search/{content}&apos;, function ($content) {    //直接输出数组data，限制1000条    // $res = App\Ques::search($content)-&gt;take(1000)-&gt;get()-&gt;toArray();    // 分页请求  http://127.0.0.1:8000/es/机器学习?page=1    $res = App\Ques::search($content)-&gt;paginate(100)-&gt;toArray();    dd($res);});</code></pre><h4 id="大功告成"><a href="#大功告成" class="headerlink" title="大功告成"></a>大功告成</h4><p>输出：</p><pre><code>array:12 [▼  &quot;current_page&quot; =&gt; 1  &quot;data&quot; =&gt; array:9 [▼    0 =&gt; array:9 [▼      &quot;id&quot; =&gt; 922      &quot;ques&quot; =&gt; &quot;哪些机器学习算法不需要做归一化处理？&quot;      &quot;analysis&quot; =&gt; &quot;&quot;&quot;        概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率，如决策树、rf。而像adaboost、svm、lr、KNN、KMeans之类的最优化问题就需要归一化。\r\n        我理解归一化和标准化主要是为了使计算更方便 比如两个变量的量纲不同 可能一个的数值远大于另一个那么他们同时作为变量的时候 可能会造成数值计算的问题，比如说求矩阵的逆可能很不精确 或者梯度下降法的收敛比较困难，还有如果需要计算欧式距离的话可能 量纲也需要调整 所以我估计lr 和 knn 保准话一下应该有好处。至于其他的算 ▶        一般我习惯说树形模型，这里说的概率模型可能是差不多的意思。引用自@寒小阳        &quot;&quot;&quot;      &quot;type_id&quot; =&gt; 3      &quot;diff&quot; =&gt; 0      &quot;isdelete&quot; =&gt; 1      &quot;created_time&quot; =&gt; &quot;2017-12-10 18:57:13&quot;      &quot;update_time&quot; =&gt; &quot;0000-00-00 00:00:00&quot;      &quot;is_show&quot; =&gt; 1    ]    1 =&gt; array:9 [▶]    2 =&gt; array:9 [▶]    3 =&gt; array:9 [▶]    4 =&gt; array:9 [▶]    5 =&gt; array:9 [▶]    6 =&gt; array:9 [▶]    7 =&gt; array:9 [▶]    8 =&gt; array:9 [▶]  ]  &quot;first_page_url&quot; =&gt; &quot;http://127.0.0.1:8000/search/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0?query=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;page=1&quot;  &quot;from&quot; =&gt; 1  &quot;last_page&quot; =&gt; 1  &quot;last_page_url&quot; =&gt; &quot;http://127.0.0.1:8000/search/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0?query=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;page=1&quot;  &quot;next_page_url&quot; =&gt; null  &quot;path&quot; =&gt; &quot;http://127.0.0.1:8000/search/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&quot;  &quot;per_page&quot; =&gt; 100  &quot;prev_page_url&quot; =&gt; null  &quot;to&quot; =&gt; 9  &quot;total&quot; =&gt; 9]</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>PHP使用elasticsearch搜索安装及分词方法【<a href="https://segmentfault.com/a/1190000011663833】" target="_blank" rel="external">https://segmentfault.com/a/1190000011663833】</a></p><p>Laravel中利用Scout集成Elasticsearch搜索引擎【<a href="https://segmentfault.com/a/1190000014230010】" target="_blank" rel="external">https://segmentfault.com/a/1190000014230010】</a></p><p>全文搜索引擎 Elasticsearch 入门教程【<a href="http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html】" target="_blank" rel="external">http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html】</a></p><p>laravel使用ElasticSearch进行搜索【<a href="https://blog.csdn.net/lingchen__/article/details/77884753】" target="_blank" rel="external">https://blog.csdn.net/lingchen__/article/details/77884753】</a></p><p>elasticsearch6.3.1+IK插件安装部署全攻略【<a href="https://blog.csdn.net/superheister/article/details/81296451】" target="_blank" rel="external">https://blog.csdn.net/superheister/article/details/81296451】</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="laravel" scheme="http://martist.cn/categories/laravel/"/>
    
    
      <category term="laravel" scheme="http://martist.cn/tags/laravel/"/>
    
  </entry>
  
  <entry>
    <title>MacOS 重装PHP</title>
    <link href="http://martist.cn/2018/09/27/MACBOOK/macOS%E9%87%8D%E8%A3%85PHP/"/>
    <id>http://martist.cn/2018/09/27/MACBOOK/macOS重装PHP/</id>
    <published>2018-09-26T16:00:00.000Z</published>
    <updated>2018-10-16T02:50:39.548Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h2><p>/usr/bin/ruby -e “$(curl -fsSL <a href="https://raw.githubusercontent.com/Homebrew/install/master/install" target="_blank" rel="external">https://raw.githubusercontent.com/Homebrew/install/master/install</a>)”</p><pre><code>该方式会创建 /usr/local/* 等一系列文件夹, 熟悉Linux的用户一看就明白这个文件夹是做什么</code></pre><h2 id="安装php"><a href="#安装php" class="headerlink" title="安装php"></a>安装php</h2><p>由于Homebrew仓库的更新, 将homebrew/homebrew-php合并到homebrew/core中, 同时也去掉了php各种扩展包. 甚至php安装包的名称也做了统一修改</p><p>以php7.1为例, 以前的安装方式是</p><p>  brew install php71</p><p>而现在需要按照brew的统一包名称规范</p><p>  brew install php@7.1</p><h2 id="不能用brew傻瓜安装redis扩展"><a href="#不能用brew傻瓜安装redis扩展" class="headerlink" title="不能用brew傻瓜安装redis扩展"></a>不能用brew傻瓜安装redis扩展</h2><p>2018年homebrew-php已经弃用了</p><h2 id="失效命令"><a href="#失效命令" class="headerlink" title="失效命令"></a>失效命令</h2><p>  brew tap homebrew/homebrew-php<br>  brew install php71-redis</p><p>选择pecl安装或者源码安装</p><h2 id="源码安装php-redis"><a href="#源码安装php-redis" class="headerlink" title="源码安装php-redis"></a>源码安装php-redis</h2><p>phpredis下载地址</p><p>  <a href="https://github.com/phpredis/phpredis" target="_blank" rel="external">https://github.com/phpredis/phpredis</a></p><p>解压并进入源码包</p><p>  unzip phpredis-develop.zip<br>  cd phpredis-develop</p><p>生成configure配置文件:</p><p>  sudo /usr/local/Cellar/php/7.2.11/bin/phpize/usr/local/php-7.1/bin/phpize</p><p>编译安装:</p><p>  sudo ./configure –with-php-config=/usr/local/Cellar/php/7.2.11/bin/php-config<br>  sudo make &amp;&amp; make install</p><p>配置php.ini<br>在extension后添加</p><p>  extension=redis.so</p><p>重启php</p><p>查看fpm是否存在</p><p>  ps aux|grep fpm</p><p>关闭</p><p>  sudo pkill php-fpm</p><p>启动</p><p>  sudo /usr/local/opt/php@7.2/sbin/php-fpm -D</p><h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><p>  php -m|grep redis</p><h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>  redis</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="Mac" scheme="http://martist.cn/categories/Mac/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="Mac" scheme="http://martist.cn/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>feed流的技术实现</title>
    <link href="http://martist.cn/2018/08/24/%E6%9E%B6%E6%9E%84/feed%E6%B5%81%E7%9A%84%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"/>
    <id>http://martist.cn/2018/08/24/架构/feed流的技术实现/</id>
    <published>2018-08-23T16:00:00.000Z</published>
    <updated>2018-08-27T06:21:19.072Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>我们现在好多软件都有一个类似朋友圈的功能：微博、微信、QQ…… 只要涉及到好友、粉丝这样的 app 或者是网站，一定有这样的一个功能。那这个功能是怎么样来实现的呢？</p><h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><p>简单来说，Feeds这块主要包括两块内容</p><pre><code>生成feeds更新feed</code></pre><h3 id="生成feeds"><a href="#生成feeds" class="headerlink" title="生成feeds"></a>生成feeds</h3><p>比如我们已经关注的人做了特定操作，我们需要把这些活动加入你的feeds，让你接收到。<br>比如某大牌明星发了个微博，这时候我们首先找到明星的所有关注者，然后给需要推送的关注者推送此微博，大家可以把每个人的feeds简单想象为一个个的有序列表，推送很简单，就是在每个人的列表末尾添加这个操作。</p><h3 id="更新feeds"><a href="#更新feeds" class="headerlink" title="更新feeds"></a>更新feeds</h3><p>你新关注了一个人，需要把他的活动加入已有feeds。这时候我们需要取出此人的活动历史，然后按照时间顺序把这些历史塞到你的feeds中。此操作的复杂度会比较高，需要使用合适的数据结构来达到最佳性能，目前是O(log(N))。</p><h3 id="取消关注"><a href="#取消关注" class="headerlink" title="取消关注"></a>取消关注</h3><p>你的关注点做了一些更新操作，比如你取消关注了一个人，那么他的动态就要在feeds中清除掉。</p><h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><p>我们可以在用常用的mysql设计个2个数据表，一个表存人和人的关注关系，一个表存发布动态的信息。这样通过链表查询就可以实现feeds流了。但是我们知道feeds流的数据量级应该会非常大，性能和可用性就会直线下降，单一依靠mysql实现feeds已经无法应对业务的增长。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="推模式"><a href="#推模式" class="headerlink" title="推模式"></a>推模式</h3><p>什么是推模式？推模式就是，用户A关注了用户B，用户B每发送一个动态，后台遍历用户B的粉丝，往他们粉丝的feed里面推送一条动态。</p><h3 id="拉模式"><a href="#拉模式" class="headerlink" title="拉模式"></a>拉模式</h3><p>与推模式相反，拉模式则是，用户每次刷新feed第一页，都去遍历关注的人，把最新的动态拉取回来。</p><p>但是，不管推模式还是拉模式都存在若关注数量或者粉丝数量过多，导致遍历时间太长的问题，怎么去解决 ？这里就出现了第三种模式，推拉模式。</p><h3 id="推拉模式"><a href="#推拉模式" class="headerlink" title="推拉模式"></a>推拉模式</h3><p>这是一种折中的解决方案，就是在线推，离线拉。粉丝几百上千万， 跟你发布动态同时在线的肯定也就只有那么顶天几百几千几万，何况这类大V很少，只推给在线的粉丝，离线的粉丝上线后，再去拉取动态即可！但是，不管是什么模式，每个用户都会维护一个类似发件箱跟收件箱的东西，保存自己发过的动态以及Feed动态（具体实现看下面），来完成推与拉。</p><p>而这里讲的，肯定就是推拉模式，用户A关注了用户B ， 用户B发布动态则将动态推进用户A的feed，这里使用redis的zset实现，sort为time（记得以毫秒为时间戳，秒级在数据量达到一定程度后，会有读取不到的问题，比如以时间戳为分页页码），value为具体的动态 ID（为什么是动态ID， 其实很简单， 就是因为动态的内容可以进行缓存，在redis里面全部走ID，修改动态内容也需要修改一处，动态内容可以保存在hash结构里）， 每个用户维护一个zset保存我发布的动态，一个zset保存我的feed动态，过期时间3~7天看情况而定。为什么要设计过期时间后面会细说。</p><p>OK，全局维护一个在线用户列表，怎么设计这个就自己琢磨了，为了防止用户挂后台导致与服务端为离线状态，所以最好是1~3小时未操作或者离线时间不大于3小时的，都当做在线处理，反正这个看情况定。</p><p>那么，当用户发了一条动态后，后台会有以下这些操作：<br>在线推： 异步遍历在线的粉丝，将动态ID，添加到粉丝的Feed中。<br>离线拉： 离线用户打开APP后，我们是会请求一个公共的入口接口，主做统计以及其他初始化操作，在这里，我们也开了一个异步线程，对用户进行Feed更新操作，防止用户进入APP后等待拉取时间过长，毕竟关注成千上万的人肯定有（其实万单位以下遍历都很快）。拉取过程其实就是把自己最后一条Feed的时间戳取出，去遍历关注的人的feed，将大于该时间的ID全部拉取回来。用户进入APP后，刷新即可看到最新操作。</p><p>另：如果有Feed新消息数提示的需求，可以在推拉的同时进行增加， 刷新feed时清空即可。</p><h2 id="用户feed里面过长，占用内存怎么办？"><a href="#用户feed里面过长，占用内存怎么办？" class="headerlink" title="用户feed里面过长，占用内存怎么办？"></a>用户feed里面过长，占用内存怎么办？</h2><p>我是这么处理的，一个用户的feed第一次拉取的时候，feed长度为500条，在我们APP里，相当于50页，而后的数据，都走数据库。</p><p>大页码翻页其实就是个伪需求而且耗性能的东西，用户除了第一次用这个APP，才会翻到底，第一次使用， 能有几个动态 ？而对于二次使用以上的用户，一般来讲， 翻了几页就已经到达上一次看过的地方了，所以500条数据，在关注量一般的情况下，内容已经足够消费，甚至达到疲劳，可能有关注量很大的用户他的Feed每天可能有很多很多动态，但是，不用说，肯定是做广告的，关注一堆人等着回粉，这种人更不会去消费内容，50页的内容，翻起来都累。当然，并不是说放弃了这些人，feed找不到走数据库嘛~~~~爱走不走，想走就给我翻50页再说~</p><h2 id="每个用户都维护自己的动态跟Feed队列，当用户上百万时，内存的占有量肯定不小，要怎么释放内存才合适-？"><a href="#每个用户都维护自己的动态跟Feed队列，当用户上百万时，内存的占有量肯定不小，要怎么释放内存才合适-？" class="headerlink" title="每个用户都维护自己的动态跟Feed队列，当用户上百万时，内存的占有量肯定不小，要怎么释放内存才合适 ？"></a>每个用户都维护自己的动态跟Feed队列，当用户上百万时，内存的占有量肯定不小，要怎么释放内存才合适 ？</h2><p>这里就回到上面那个问题了，为什么要给feed的key设计过期时间？为什么是设计3~7天过期时间？</p><p>原因有以下：</p><pre><code>一、一个用户3~7天不打开APP，可能已经对APP失去兴趣了，打开几率很小，或者已经被卸载了，没有存在的意义了。二、3~7天未登陆APP，关注的人发的动态也不少了，Feed未拉取回来的数据肯定也不少，那么这时候去遍历其实拉取量很大，那么还不如直接全部重新拉一边或者拉取用户最后登陆时间后产出的数据。</code></pre><p>到这里，其实已经差不多了，大部分业务逻辑已经足够满足，并且速度也理想，目前我们线上这种模式走了半年，feed一般都是10~80ms响应完毕。</p><pre><code>&lt;?php echo &apos;求关注 求喜欢&apos;;?&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      谈谈我对feed的理解
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="web" scheme="http://martist.cn/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>swoole 安装</title>
    <link href="http://martist.cn/2018/08/10/PHP/swoole%E5%AE%89%E8%A3%85%E5%92%8C%E5%85%A5%E9%97%A8/"/>
    <id>http://martist.cn/2018/08/10/PHP/swoole安装和入门/</id>
    <published>2018-08-09T16:00:00.000Z</published>
    <updated>2018-09-05T07:10:07.524Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="swoole-安装"><a href="#swoole-安装" class="headerlink" title="swoole 安装"></a>swoole 安装</h2><h3 id="homestead命令回忆"><a href="#homestead命令回忆" class="headerlink" title="homestead命令回忆"></a>homestead命令回忆</h3><p>重新加载配置</p><pre><code>vagrant provision </code></pre><p>启动</p><pre><code>vagrant up </code></pre><p>重启</p><pre><code>vagrant reload</code></pre><h3 id="平滑重启php-fpm"><a href="#平滑重启php-fpm" class="headerlink" title="平滑重启php-fpm"></a>平滑重启php-fpm</h3><p>master进程可以理解以下信号</p><pre><code>INT, TERM 立刻终止QUIT 平滑终止USR1 重新打开日志文件USR2 平滑重载所有worker进程并重新载入配置和二进制模块</code></pre><p>查找fpm的pid</p><pre><code># ps aux|grep php-fpmroot     21891  0.0  0.0 112660   960 pts/3    R+   16:18   0:00 grep --color=auto php-fpmroot     42891  0.0  0.1 182796  1220 ?        Ss   4月18   0:19 php-fpm: master process (/usr/local/php/etc/php-fpm.conf)nobody   42892  0.0  0.6 183000  6516 ?        S    4月18   0:07 php-fpm: pool wwwnobody   42893  0.0  0.6 183000  6508 ?        S    4月18   0:17 php-fpm: pool www</code></pre><p>平滑重启php-fpm</p><pre><code>kill -USR2 42891</code></pre><h3 id="swoole下载"><a href="#swoole下载" class="headerlink" title="swoole下载"></a>swoole下载</h3><p>下载地址<br><a href="https://github.com/swoole/swoole-src/releases" target="_blank" rel="external">https://github.com/swoole/swoole-src/releases</a></p><h3 id="编译和安装"><a href="#编译和安装" class="headerlink" title="编译和安装"></a>编译和安装</h3><p>下载源代码包后，在终端进入源码目录</p><pre><code>cd swoolephpize./configuremake sudo make install</code></pre><h3 id="配置php-ini"><a href="#配置php-ini" class="headerlink" title="配置php.ini"></a>配置php.ini</h3><p>编译安装成功后，修改php.ini加入</p><pre><code>extension=swoole.so</code></pre><p>homestead中有fpm的php.ini和cli的php.ini.</p><p>通过php -m或phpinfo()来查看是否成功加载了swoole，如果没有可能是php.ini的路径不对，可以使用php –ini来定位到php.ini的绝对路径。</p><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><p>查看端口是否被占用 </p><pre><code>netstat -anp | grep 9051</code></pre><p>websocket是基于tcp的一种新的网络协议，实现了浏览器和服务器全双工通信。</p><p>websocket协议的特点是允许服务器主动发送信息给客户端，而http协议的通信只能有客户端发起。</p><p>在sever配置域名的地方，‘0.0.0.0’代表了本机的所有地址，</p><p>swoole和websocket的官网，都有案例，websocket的官网有很多js案例。</p><h2 id="学习地址"><a href="#学习地址" class="headerlink" title="学习地址"></a>学习地址</h2><p><a href="https://wiki.swoole.com" target="_blank" rel="external">https://wiki.swoole.com</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="swoole" scheme="http://martist.cn/tags/swoole/"/>
    
  </entry>
  
  <entry>
    <title>数组合并</title>
    <link href="http://martist.cn/2018/08/06/PHP/%E6%95%B0%E7%BB%84%E5%90%88%E5%B9%B6/"/>
    <id>http://martist.cn/2018/08/06/PHP/数组合并/</id>
    <published>2018-08-05T16:00:00.000Z</published>
    <updated>2018-08-06T10:56:49.383Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="array-merge"><a href="#array-merge" class="headerlink" title="array_merge()"></a>array_merge()</h2><pre><code>$a1=array(&quot;red&quot;,&quot;green&quot;);$a2=array(&quot;blue&quot;,&quot;yellow&quot;);print_r(array_merge($a1,$a2));Array ( [0] =&gt; red [1] =&gt; green [2] =&gt; blue [3] =&gt; yellow ) </code></pre><p>如果两个或更多个数组元素有相同的键名，则最后的元素会覆盖其他元素。<br>输入多个数组键名是整数，则该函数将返回带有整数键名的新数组，其键名以 0 开始进行重新索引。<br>array_merge（）与 array_merge_recursive() 函数之间的不同是在处理两个或更多个数组元素有相同的键名的情况。</p><h2 id="array-merge-recursive"><a href="#array-merge-recursive" class="headerlink" title="array_merge_recursive()"></a>array_merge_recursive()</h2><p>（1）array_merge_recursive() 不会进行键名覆盖，而是将多个相同键名的值递归组成一个数组。</p><pre><code>$a1=array(&quot;a&quot;=&gt;&quot;red&quot;,&quot;b&quot;=&gt;&quot;green&quot;);$a2=array(&quot;c&quot;=&gt;&quot;blue&quot;,&quot;b&quot;=&gt;&quot;yellow&quot;);print_r(array_merge_recursive($a1,$a2));Array ( [a] =&gt; red [b] =&gt; Array ( [0] =&gt; green [1] =&gt; yellow ) [c] =&gt; blue ) </code></pre><p>（2）输入多个数组键名是整数，则该函数将返回带有整数键名的新数组，其键名以 0 开始进行重新索引。</p><pre><code>$a1=array(&quot;2&quot;=&gt;&quot;red&quot;,&quot;9&quot;=&gt;&quot;green&quot;);$a2=array(&quot;99&quot;=&gt;&quot;blue&quot;,&quot;111&quot;=&gt;&quot;yellow&quot;);print_r(array_merge_recursive($a1,$a2));Array(    [0] =&gt; red    [1] =&gt; green    [2] =&gt; blue    [3] =&gt; yellow)</code></pre><h2 id="array-combine"><a href="#array-combine" class="headerlink" title="array_combine()"></a>array_combine()</h2><p>通过合并两个数组来创建一个新数组，其中的一个数组元素为键名，另一个数组元素为键值：</p><pre><code>$fname=array(&quot;Bill&quot;,&quot;Steve&quot;,&quot;Mark&quot;);$age=array(&quot;60&quot;,&quot;56&quot;,&quot;31&quot;);$c=array_combine($fname,$age);print_r($c);Array ( [Bill] =&gt; 60 [Steve] =&gt; 56 [Mark] =&gt; 31 ) </code></pre><h2 id="合并数组并保留键值的方法"><a href="#合并数组并保留键值的方法" class="headerlink" title="合并数组并保留键值的方法"></a>合并数组并保留键值的方法</h2><pre><code>$form_data1 = array(11=&gt;&apos;A&apos;,12=&gt;&apos;B&apos;,13=&gt;&apos;C&apos;,14=&gt;&apos;D&apos;);$form_data2 = array(25=&gt;&apos;B&apos;,26=&gt;&apos;A&apos;,27=&gt;&apos;D&apos;,28=&gt;&apos;C&apos;);$result = $form_data1 + $form_data2;print_r($result);Array(    [11] =&gt; A    [12] =&gt; B    [13] =&gt; C    [14] =&gt; D    [25] =&gt; B    [26] =&gt; A    [27] =&gt; D    [28] =&gt; C)</code></pre><p>使用 “+” 运算符合并数组，可以保留数组的键值，如果合并的数组中含有相同的键值，前面的键值对覆盖后面的键值对。<br>这里和array_merge（）相反。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="常识" scheme="http://martist.cn/tags/%E5%B8%B8%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>DHCP</title>
    <link href="http://martist.cn/2018/07/30/WEB/DHCP%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://martist.cn/2018/07/30/WEB/DHCP的理解/</id>
    <published>2018-07-29T16:00:00.000Z</published>
    <updated>2018-07-31T10:41:03.120Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="类比"><a href="#类比" class="headerlink" title="类比"></a>类比</h2><p>为了便于理解，我们把DHCP客户机比做餐馆里的客人，DHCP服务器比做服务员（一个餐馆里也可以有多个服务员），IP地址比做客户需要的食物。可以这样描述整个过程：</p><p>客人走进餐馆，问：“有没有服务员啊？”（DHCP discover），<br>多个服务员同时回答：“有，我这有鸡翅”“有，我这有汉堡”（DHCP offer）。<br>客人说：“好吧，我要一份汉堡”（DHCP request，这个客人比较死板，总是选择第一次听到的食物），<br>端着汉堡的服务员回应了一声：“来啦”（DHCP ack），并把食物端到客人面前，供其享用（将网卡和IP地址绑定）。<br>客人下次来的时候，就直接找上次那个服务员点自己喜欢的汉堡了（DHCP request），如果还有汉堡，服务员会再次确认并上菜（DHCP ack），而如果已经卖完了，服务员则会告诉客人：“不好意思，已经卖完了”（DHCP nack）。<br>当然，服务员隔一段时间会来收拾一次桌子，除非客人特别说明这菜还要继续吃的，服务员会将剩菜端走。</p><h2 id="DHCP"><a href="#DHCP" class="headerlink" title="DHCP"></a>DHCP</h2><p>DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一个局域网的网络协议，使用UDP协议工作。<br>主要有两个用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。</p><h2 id="DHCP的简介"><a href="#DHCP的简介" class="headerlink" title="DHCP的简介"></a>DHCP的简介</h2><p>动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）是用于对多个客户计算机集中分配IP地址以及IP地址相关的信息的协议，这样就能将IP地址和TCP/IP的设置统一管理起来，而避免不必要的地址冲突的问题，因此常常用在网络中对众多计算机的管理方面，节省了网络管理员手工设置和分配地址的麻烦。</p><p>除了能够方便管理之外，DHCP还能略微达到节省IP地址的目的。假设网络中有50个计算机，但只有40个 IP地址，但是这50台计算机不会同时启动，IP地址应该满足要求。DHCP也能用于统一设置其他的一些IP设置，如缺省路由、DNS服务器等等，使用它能减少一个大型网络的管理任务。</p><p>DHCP是从原有的BootP协议发展起来的，原来的目的是为无盘工作站分配IP地址的协议，当前更多的用于集中管理IP地址。然而DHCP协议也有其缺点，例如一台DHCP客户计算机没有一个固定的IP地址，而对于提供网络服务的服务器来讲，经常变化的IP地址并不适合。并且当前的DNS协议并不能和DHCP协作，为DHCP客户直接提供主机名解析任务。</p><p>DHCP服务优点：网络管理员可以验证IP地址和其它配置参数，而不用去检查每个主机；DHCP不会同时租借相同的IP地址给两台主机；DHCP管理员可以约束特定的计算机使用特定的IP地址；可以为每个DHCP作用域设置很多选项；客户机在不同子网间移动时不需要重新设置IP地址。</p><p>但同时也存在不少缺点：DHCP不能发现网络上非DHCP客户机已经在使用的IP地址；当网络上存在多个DHCP服务器时，一个DHCP服务器不能查出已被其它服务器租出去的IP地址；DHCP服务器不能跨路由器与客户机通信，除非路由器允许BOOTP转发。</p><h2 id="工作过程"><a href="#工作过程" class="headerlink" title="工作过程"></a>工作过程</h2><p>DHCP工作时要求客户机和服务器进行交互，由客户机通过广播向服务器发起申请IP地址的请求，然后由服务器分配一个IP地址以及其他的TCP/IP设置信息。整个过程可以分为以下步骤：</p><p>IP地址租用申请：DHCP客户机的TCP/IP首次启动时，就要执行DHCP客户程序，以进行TCP/IP 的设置。由于此时客户机的TCP/IP还没有设置完毕，就只能使用广播的方式发送DHCP请求信息包，广播包使用 UDP端口67和68进行发送，广播信息中包括了客户机的网络界面的硬件地址和计算机名字，以提供DHCP服务器进行分配。</p><p>IP地址租用提供：当接收到DHCP客户机的广播信息之后，所有的DHCP服务器均为这个客户机分配一个合适的IP地址，将这些IP地址、网络掩码、租用时间等信息，按照DHCP客户提供的硬件地址发送回DHCP客户机。这个过程中对DHCP服务器没有对客户计算机进行限制，因此客户机能收到多个IP地址提供信息。</p><p>IP地址租用选择：由于客户机接收到多个服务器发送的多个IP地址提供信息，客户机将选择一个IP地址，拒绝其他提供的IP地址，以便这些地址能分配给其他客户。客户机将向它选择的服务器发送选择租用信息。</p><p>IP地址租用确认：服务器将收到客户的选择信息，如果也没有例外发生，将回应一个确认信息，将这个IP地址真正分配给这个客户机。客户机就能使用这个IP地址及相关的TCP/IP数据，来设置自己的TCP/IP堆栈。</p><p>更新租用：DHCP中，每个IP地址是有一定租期的，若租期已到，DHCP服务器就能够将这个IP地址重新分配给其他计算机。因此每个客户计算机应该提前续租它已经租用的IP地址，服务器将回应客户机的请求并更新该客户机的租期设置。一旦服务器返回不能续租的信息，那么DHCP客户机只能在租期到达时放弃原有的IP地址，重新申请一个新 IP地址。为了避免发生问题，续租在租期达到50%时就将启动，如果没有成功将不断启动续租请求过程。</p><p>释放IP地址租用：客户机可以主动释放自己的IP地址请求，也可以不释放，但也不续租，等待租期过期而释放占用的IP地址资源。</p><p>由于DHCP依赖于广播信息，因此一般的情况下，客户机和服务器应该位于同一个网络之内。然而可以设置网络中的路由器为可以转发BootP广播包，使得服务器和客户机可以位于两个不同的网络中。然而配置转发广播信息，不是一个很好的解决办法，更好的办法为使用DHCP中转计算机，DHCP中转计算机和DHCP客户机位于同一个网络中，来回应客户机的租用请求，然而它不维护DHCP数据和拥有IP地址资源，它只是将请求通过TCP/IP转发给位于另一个网络上的DHCP服务器，进行实际的IP地址分配和确认。</p><h2 id="客户端向DHCP-服务器请求IP-地址的4-个步骤"><a href="#客户端向DHCP-服务器请求IP-地址的4-个步骤" class="headerlink" title="客户端向DHCP 服务器请求IP 地址的4 个步骤"></a>客户端向DHCP 服务器请求IP 地址的4 个步骤</h2><pre><code>发现阶段（DHCP客户端在网络中广播发送DHCP DISCOVER请求报文，发现DHCP服务器，请求IP地址租约）提供阶段（DHCP服务器通过DHCP OFFER报文向DHCP客户端提供IP地址预分配）选择阶段（DHCP客户端通过DHCP REQUEST报文确认选择第一个DHCP服务器为它提供IP地址自动分配服务）确认阶段（被选择的DHCP服务器通过DHCP ACK报文把在DHCP OFFER报文中准备的IP地址租约给对应DHCP客户端）</code></pre><h2 id="路由器dhcp可以分配多少个ip"><a href="#路由器dhcp可以分配多少个ip" class="headerlink" title="路由器dhcp可以分配多少个ip"></a>路由器dhcp可以分配多少个ip</h2><p>一个C类地址可以分配256个，其中2个不可用，一个是网关，一个是网络地址。B类地址可以分配65536个，也是两个不可用。 </p><h2 id="分配ip地址的方式"><a href="#分配ip地址的方式" class="headerlink" title="分配ip地址的方式"></a>分配ip地址的方式</h2><p>DHCP服务器具有三种IP的分配方式，手动分配，自动分配和动态分配。其中动态分配功能最为强大，配置也最为烦琐。目前的DHCP服务器一般支持全部的几种分配方式或者是其中的两种。<br>手动分配：在手动分配中，网络管理员在DHCP服务器通过手工方法配置DHCP客户机的IP地址。当DHCP客户机要求网络服务时，DHCP服务器把手工配置的IP地址传递给DHCP客户机。<br>自动分配：在自动分配中，不需要进行任何的IP地址手工分配。当DHCP客户机第一次向DHCP服务器租用到IP地址后，这个地址就永久地分配给了该DHCP客户机，而不会再分配给其他客户机。<br>动态分配：当DHCP客户机向DHCP服务器租用IP地址时，DHCP服务器只是暂时分配给客户机一个IP地址。只要租约到期，这个地址就会还给DHCP服务器，以供其他客户机使用。如果DHCP客户机仍需要一个IP地址来完成工作，则可以再要求另外一个IP地址。<br>动态分配方法是惟一能够自动重复使用IP地址的方法，它对于暂时连接到网上的DHCP客户机来说尤其方便，对于永久性与网络连接的新主机来说也是分配IP地址的好方法。DHCP客户机在不再需要时才放弃IP地址，如DHCP客户机要正常关闭时，它可以把IP地址释放给DHCP服务器，然后DHCP服务器就可以把该IP地址分配给申请IP地址的DHCP客户机。</p><h2 id="公司内所有电脑ip相同是为什么"><a href="#公司内所有电脑ip相同是为什么" class="headerlink" title="公司内所有电脑ip相同是为什么"></a>公司内所有电脑ip相同是为什么</h2><p>IP分为局域网和广域网，一般局域网内部为您路由器分配的DHCP服务。<br>公司内所有电脑ip相同是外网IP，它确实是同一个。<br>公司只开了一个上网帐号（宽带帐号），然后用路由器再分出来的，所以所有的电脑用的都是同一个公网IP，但是每台电脑上显示的IP是不一样的，应该是如192.168.1.103这样的一类局域网IP。</p><h2 id="家里的拨号上网"><a href="#家里的拨号上网" class="headerlink" title="家里的拨号上网"></a>家里的拨号上网</h2><p>家里的拨号上网的ip是独立的ip，不与其他家庭的共享。<br>和公司的进入的一个宽带信号是平级的，在家里使用的路由器发射wifi信号，</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="web" scheme="http://martist.cn/categories/web/"/>
    
    
      <category term="web" scheme="http://martist.cn/tags/web/"/>
    
      <category term="协议" scheme="http://martist.cn/tags/%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>gitlab配置https</title>
    <link href="http://martist.cn/2018/07/20/%E8%BF%90%E7%BB%B4&amp;%E5%B7%A5%E4%BD%9C/gitlab%E7%9A%84%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/"/>
    <id>http://martist.cn/2018/07/20/运维&amp;工作/gitlab的自签名证书/</id>
    <published>2018-07-19T16:00:00.000Z</published>
    <updated>2018-07-20T10:35:10.941Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a> </p><pre><code>2018-07-20更新自签名证书生成失效了，重新生成的也不能用，改用了godaddy的新证书，才好了。</code></pre><hr><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><pre><code>$ sudo vim /etc/gitlab/gitlab.rb#13行的 http &gt;&gt; httpsexternal_url &apos;https://ip:port&apos;#修改nginx配置 810行nginx[&apos;redirect_http_to_https&apos;] =truenginx[&apos;ssl_certificate&apos;] = &quot;/etc/gitlab/ssl/server.crt&quot;nginx[&apos;ssl_certificate_key&apos;] = &quot;/etc/gitlab/ssl/server.key&quot;</code></pre><h2 id="生成秘钥与证书"><a href="#生成秘钥与证书" class="headerlink" title="生成秘钥与证书"></a>生成秘钥与证书</h2><pre><code>#秘钥脚本，将以下内容保存为shell脚本，然后运行#出现提示输入信息的地方输入信息，先输入域名然后4次证书密码，任意密码，四次保持一致。#!/bin/sh# create self-signed server certificate:read -p &quot;Enter your domain [139.199.125.93]: &quot; DOMAINecho &quot;Create server key...&quot;openssl genrsa -des3 -out $DOMAIN.key 1024echo &quot;Create server certificate signing request...&quot;SUBJECT=&quot;/C=US/ST=Mars/L=iTranswarp/O=iTranswarp/OU=iTranswarp/CN=$DOMAIN&quot;openssl req -new -subj $SUBJECT -key $DOMAIN.key -out $DOMAIN.csrecho &quot;Remove password...&quot;mv $DOMAIN.key $DOMAIN.origin.keyopenssl rsa -in $DOMAIN.origin.key -out $DOMAIN.keyecho &quot;Sign SSL certificate...&quot;openssl x509 -req -days 3650 -in $DOMAIN.csr -signkey $DOMAIN.key -out $DOMAIN.crtecho &quot;TODO:&quot;echo &quot;Copy $DOMAIN.crt to /etc/nginx/ssl/$DOMAIN.crt&quot;echo &quot;Copy $DOMAIN.key to /etc/nginx/ssl/$DOMAIN.key&quot;echo &quot;Add configuration in nginx:&quot;echo &quot;server {&quot;echo &quot;    ...&quot;echo &quot;    listen 443 ssl;&quot;echo &quot;    ssl_certificate     /etc/nginx/ssl/$DOMAIN.crt;&quot;echo &quot;    ssl_certificate_key /etc/nginx/ssl/$DOMAIN.key;&quot;echo &quot;}&quot;</code></pre><h2 id="执行成功后生成文件如下"><a href="#执行成功后生成文件如下" class="headerlink" title="执行成功后生成文件如下"></a>执行成功后生成文件如下</h2><pre><code>$ ls139.199.125.93.crt  139.199.125.93.origin.key             nginx-1.7.12   vim-7.3.tar.bz2139.199.125.93.csr  apache-tomcat-8.5.28.tar.gz           ssl_genKey.sh  vimcdoc-1.8.0139.199.125.93.key  gitlab-ce-10.0.0-ce.0.el7.x86_64.rpm  vim73          vimcdoc-1.8.0.tar.gz</code></pre><h2 id="移动到相应的位置"><a href="#移动到相应的位置" class="headerlink" title="移动到相应的位置"></a>移动到相应的位置</h2><pre><code>sudo mkdir -p /etc/gitlab/sslsudo chmod 700 /etc/gitlab/ssl/ -Rsu cp 139.199.125.93.crt /etc/gitlab/ssl/server.crtsudo cp 139.199.125.93.key /etc/gitlab/ssl/server.key</code></pre><h2 id="重建配置"><a href="#重建配置" class="headerlink" title="重建配置"></a>重建配置</h2><pre><code>sudo gitlab-ctl reconfigure</code></pre><h2 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h2><pre><code>sudo gitlab-ctl restart</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.jianshu.com/p/4111534b339f" target="_blank" rel="external">https://www.jianshu.com/p/4111534b339f</a><br><a href="https://www.cnblogs.com/xieshuang/p/8488458.html" target="_blank" rel="external">https://www.cnblogs.com/xieshuang/p/8488458.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="git" scheme="http://martist.cn/categories/git/"/>
    
    
      <category term="git" scheme="http://martist.cn/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>PHP 代码简洁之道 （ PHP Clean Code）</title>
    <link href="http://martist.cn/2018/07/06/PHP/php%E4%BB%A3%E7%A0%81%E7%AE%80%E6%B4%81%E4%B9%8B%E9%81%93/"/>
    <id>http://martist.cn/2018/07/06/PHP/php代码简洁之道/</id>
    <published>2018-07-05T16:00:00.000Z</published>
    <updated>2018-07-08T10:50:30.588Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><p>附地址：<br><a href="https://blog.csdn.net/zhu_lizhen/article/details/79267432#t5" target="_blank" rel="external">https://blog.csdn.net/zhu_lizhen/article/details/79267432#t5</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="常识" scheme="http://martist.cn/tags/%E5%B8%B8%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>设计模式的原则</title>
    <link href="http://martist.cn/2018/06/26/PHP/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8E%9F%E5%88%99/"/>
    <id>http://martist.cn/2018/06/26/PHP/设计模式的原则/</id>
    <published>2018-06-25T16:00:00.000Z</published>
    <updated>2018-06-27T01:32:16.033Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a><br>列举下常见设计模式和原则</p><h2 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h2><pre><code>1、Abstract Factory (抽象工厂模式)2、Adapter 适配器模式3、Bridge:桥梁模式4、Builder:建筑者模式5、Chain of Responsibility:职责链模式6、Command 命令模式7、Composite:组合模式8、Decorator:装饰模式9、Facade:外观模式10、Factory Method:工厂模式11、Flyweight:享元模式12、Interpreter:解释器模式13、Iterator:迭代器模式14、Mediator:中介模式15、Memento:备忘录模式16、观察者模式（搞懂这个，对搞懂.net规范下的委托很重要，个人理解）17、Prototype:原型模式18、Proxy:代理模式19、Singleton:单例模式20、State:状态模式21、Strategy:策略模式22、Template Method:模板方法模式23、Visitor:访问者模式</code></pre><h2 id="设计模式原则"><a href="#设计模式原则" class="headerlink" title="设计模式原则"></a>设计模式原则</h2><pre><code>1、单一原则2、里氏替换原则3、依赖倒置原则4、接口隔离原则5、迪米特法则6、开闭原则</code></pre><h3 id="细则"><a href="#细则" class="headerlink" title="细则"></a>细则</h3><h4 id="单一职责原则（Single-Responsibility-Principle）"><a href="#单一职责原则（Single-Responsibility-Principle）" class="headerlink" title="单一职责原则（Single Responsibility Principle）"></a>单一职责原则（Single Responsibility Principle）</h4><blockquote><p>应该有且只有一个原因引起类的变化</p></blockquote><p>注意 : 这里的类不光指类,也适用于方法和接口,比如我们常说的一个方法实现一个功能</p><h4 id="里氏代换原则（Liskov-Substitution-Principle）"><a href="#里氏代换原则（Liskov-Substitution-Principle）" class="headerlink" title="里氏代换原则（Liskov Substitution Principle）"></a>里氏代换原则（Liskov Substitution Principle）</h4><blockquote><p>只要父类出现的地方子类就一定可以出现,而且替换为子类也不会出现任何异常或错误,使用者不需要知道是父类还是子类.但是返回来就不行了,有子类出现的地方,</p></blockquote><p>不一定能使用父类</p><p>使用规范 : </p><pre><code>子类必须完全实现父类的方法,如果子类无法完全实现父类的方法,则建议断开父子继承关系,采用依赖 | 聚集 | 组合 等关系来代替子类可以有自己的个性覆盖或实现父类的方法时,输入参数可以被放大,比如父类中有一个方法的输入参数是 HashMap,子类的参数可以是 Map 类型,这样父类就可以被子类替换,如果反过来,则违背了里氏替换原则,所以子类中方法的前置条件必须与父类的被覆写的方法的前置条件相同或者更宽松覆写或实现父类的方法时,输出结果可以被缩小,也就是说如果父类方法返回的类型 T,子类的相同方法(重载或覆写)的返回值类型 S,S 和 T 要么同类型,要么 S 是 T 的子类;跟上面的道理一样    </code></pre><p>注意 : 采用里氏替换原则时,尽量避免子类的”个性”,一旦子类有了”个性”,子类和父类的关系就会变得不好调和</p><h4 id="依赖倒置原则（Dependence-Inversion-Principle）"><a href="#依赖倒置原则（Dependence-Inversion-Principle）" class="headerlink" title="依赖倒置原则（Dependence Inversion Principle）"></a>依赖倒置原则（Dependence Inversion Principle）</h4><blockquote><p>依赖倒置原则包含三个含义</p></blockquote><pre><code>高层模块不应该依赖低层模块,两者都应该依赖其抽象抽象不应该依赖细节细节应该依赖抽象</code></pre><p>高层模块和低层模块比较好理解,每一个逻辑都是由原子逻辑组成的,不可分割的原子逻辑是低层模块,原子逻辑再组装就是高层模块;<br>抽象指的是接口或者抽象类,两者都不能直接实例化;<br>细节就是实现类,实现接口或继承抽象类而产生的类就是细节,其特点是可以被实例化;</p><p>依赖倒置原则在 Java 中的实现是表现是:</p><pre><code>模块间的依赖通过抽象发生,实现类之间不发生直接的依赖关系,其依赖关系是通过接口或抽象类产生的;接口或抽象类不依赖于实现类实现类依赖接口或抽象类</code></pre><p>这也是面向接口编程的精髓之一</p><p>遵循的规则 : </p><pre><code>每个类尽量都有接口或抽象类,或者两者都有变量的表面类型尽量是接口或者抽象类任何类都不应该从具体类派生尽量不要覆写基类的方法,如果基类是一个抽象类,而且这个方法已经实现了,子类尽量不要覆写结合里氏替换原则使用接口负责定义 public 属性和方法,并且声明与其他对象的依赖关系,抽象类负责公共构造部分的实现,实现类准确的实现业务逻辑</code></pre><h4 id="接口隔离原则（Interface-Segregation-Principle）"><a href="#接口隔离原则（Interface-Segregation-Principle）" class="headerlink" title="接口隔离原则（Interface Segregation Principle）"></a>接口隔离原则（Interface Segregation Principle）</h4><blockquote><p>实例接口在 Java 中声明一个类,然后用 new 关键字产生一个实例,它是对一类事物的描述,可以看成是一个接口；类接口使用 interface 定义的接口</p></blockquote><p>隔离的的理解 : </p><pre><code>客户端不应该依赖它不需要的接口类之间的依赖关系应该建立在最小的接口上概括 : 建立单一接口,不要建立臃肿庞大的接口,也就是接口尽量细化,接口中的方法尽量少</code></pre><p>这个是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。</p><p>接口隔离原则的约束条件 : </p><pre><code>接口要高内聚,意思就是提高接口,类,模块的处理能力,减少对外的交互,再具体一点就是在接口中尽量减少对外的 public 方法,通过业务逻辑压缩接口中的 public 方法定制服务,就是单独为一个个体提供优良的服务,比如我们写用户模块的时候,需要给用户提供查询信息,修改密码,注册用户等信息,当管理员执行相同操作的时候,一般人会复用这些方法,  然后在这个的基础上再增加管理员自己的方法,这种设计方法肯定是有问题的,这样设计,当你修改了普通用户调用的接口实现时,管理员的实现也会发生不可预测的改变,我们应该为管理  员单独写一个接口接口设计是有限度的,接口的设计粒度越小,系统越灵活,这是肯定的,但灵活的同时带来的问题是 结构复杂化,开发难度增加, 可维护性降低一个接口只服务于一个子模块或业务逻辑已经被污染了的接口,尽量去修改 ,若修改的风险较大,则采用适配器模式进行转化处理了解环境,拒绝盲从,不要一味的去套设计模式,有的时候不用比用了更好,也不要去照搬别人的设计方法,他的方法到你这不一定效果就好,毕竟业务逻辑不一样</code></pre><h4 id="迪米特法则（Demeter-Principle）"><a href="#迪米特法则（Demeter-Principle）" class="headerlink" title="迪米特法则（Demeter Principle）"></a>迪米特法则（Demeter Principle）</h4><blockquote><p>迪米特法则也叫最少知识原则,含义是 一个对象应该对其他对象有最少的了解,这个应该很好理解,就是降低各模块之间的耦合</p></blockquote><h4 id="开闭原则（Open-Close-Principle）"><a href="#开闭原则（Open-Close-Principle）" class="headerlink" title="开闭原则（Open Close Principle）"></a>开闭原则（Open Close Principle）</h4><blockquote><p>一个软件实体如类,模块和函数应该对扩展开放,对修改关闭,开闭原则也是其他五个原则的基石</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/kafeibuku/p/5671394.html" target="_blank" rel="external">https://www.cnblogs.com/kafeibuku/p/5671394.html</a><br><a href="https://www.jianshu.com/p/a489dd5ad1fe" target="_blank" rel="external">https://www.jianshu.com/p/a489dd5ad1fe</a><br><a href="https://www.cnblogs.com/lina520/p/7993478.html" target="_blank" rel="external">https://www.cnblogs.com/lina520/p/7993478.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="php" scheme="http://martist.cn/categories/php/"/>
    
    
      <category term="php" scheme="http://martist.cn/tags/php/"/>
    
      <category term="常识" scheme="http://martist.cn/tags/%E5%B8%B8%E8%AF%86/"/>
    
  </entry>
  
  <entry>
    <title>网络协议须知</title>
    <link href="http://martist.cn/2018/06/25/WEB/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E9%A1%BB%E7%9F%A5/"/>
    <id>http://martist.cn/2018/06/25/WEB/网络协议须知/</id>
    <published>2018-06-24T16:00:00.000Z</published>
    <updated>2018-07-10T11:14:56.083Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="OSI模型"><a href="#OSI模型" class="headerlink" title="OSI模型"></a>OSI模型</h2><pre><code>OSI七层模型是万能的国际标准化组织(ISO)提出的一个试图使各种计算机在世界范围内互连的理想标准，说白了理想和现实的差距就是七层模型和五层模型的差距。具体分类如下表：</code></pre><table><thead><tr><th>七层模型</th><th style="text-align:center">五层模型</th><th style="text-align:right">四层模型</th></tr></thead><tbody><tr><td>应用层</td><td style="text-align:center"></td><td style="text-align:right"></td></tr><tr><td>表示层</td><td style="text-align:center">应用层</td><td style="text-align:right">应用层</td></tr><tr><td>会话层</td><td style="text-align:center"></td></tr></tbody></table><p>传输层  | 传输层  | 传输层|<br>| 网络层| 网络层 | 网络层 |<br>|数据链路层 | 数据链路层 |     链接层/实体层 |<br>|物理层 | 物理层 |  |</p><p> 七层模型的上三层归为应用层即为TCP/IP五层模型，五层模型的下两层归为链接层或者说实体层即为四层模型。</p><p> 从本质上来区分，HTTP，WebSocket，TCP，UDP，IP都是协议，而TCP/IP是不同协议的组合，你也可以称之为协议栈，协议族，TCP/IP模型。</p><p> 而Socket（套接字）才是真正能操作的东西。Socket的本质是API，是先人对TCP/IP协议族的抽象或者说封装，它就像一个门面，给你一个操作TCP/IP协议的入口，来建立Socket连接。值得一提的是，此Socket是指网络编程下的Socket，而不是Unix中的Socket。虽然概念相似，但是Unix中的Socket不是基于这些乱七八糟的协议，而是基于操作系统本身的文件系统。</p><p>从分层上来区分，HTTP，WebSocket是应用层协议，TCP，UDP是传输层协议，IP是网络层协议。</p><h2 id="IP"><a href="#IP" class="headerlink" title="IP"></a>IP</h2><blockquote><p>网络之间互连的协议(Internet Protoco)</p></blockquote><p>网络之间互连的协议也就是为计算机网络相互连接进行通信而设计的协议。在因特网中，它是能使连接到网上的所有计算机网络实现相互通信的一套规则，规定了计算机在因特网上进行通信时应当遵守的规则。任何厂家生产的计算机系统，只要遵守IP协议就可以与因特网互连互通。IP地址具有唯一性，根据用户性质的不同，可以分为5类。另外，IP还有进入防护，知识产权，指针寄存器等含义。</p><p>IP 是无连接的</p><p>IP 用于计算机之间的通信。</p><p>IP 是无连接的通信协议。它不会占用两个正在通信的计算机之间的通信线路。这样，IP 就降低了对网络线路的需求。每条线可以同时满足许多不同的计算机之间的通信需要。</p><p>通过 IP，消息（或者其他数据）被分割为小的独立的包，并通过因特网在计算机之间传送。</p><p>IP 负责将每个包路由至它的目的地。<br>IP地址</p><p>每个计算机必须有一个 IP 地址才能够连入因特网。</p><p>每个 IP 包必须有一个地址才能够发送到另一台计算机。</p><p>网络上每一个节点都必须有一个独立的Internet地址（也叫做IP地址）。现在，通常使用的IP地址是一个32bit的数字，也就是我们常说的IPv4标准，这32bit的数字分成四组，也就是常见的255.255.255.255的样式。IPv4标准上，地址被分为五类，我们常用的是B类地址。具体的分类请参考其他文档。需要注意的是IP地址是网络号+主机号的组合，这非常重要。</p><p>TCP/IP 使用 32 个比特来编址。一个计算机字节是 8 比特。所以 TCP/IP 使用了 4 个字节。<br>一个计算机字节可以包含 256 个不同的值：<br>00000000、00000001、00000010、00000011、00000100、00000101、00000110、00000111、00001000 ……. 直到 11111111。<br>现在，你知道了为什么 TCP/IP 地址是介于 0 到 255 之间的 4 个数字。</p><h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><blockquote><p>传送控制协议(Transmission Control Protocol)</p></blockquote><p> TCP是面向连接的一种传输控制协议。<br> TCP连接之后，客户端和服务器可以互相发送和接收消息，在客户端或者服务器没有主动断开之前，连接一直存在，故称为长连接。<br> 特点：连接有耗时，传输数据无大小限制，准确可靠，先发先至。</p><h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h3><p>所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示：<br>TCP三次握手.png</p><p>（1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。</p><p>（2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。</p><p>（3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。</p><h4 id="简单来说，就是"><a href="#简单来说，就是" class="headerlink" title="简单来说，就是"></a>简单来说，就是</h4><p>1、建立连接时，客户端发送SYN包（SYN=i）到服务器，并进入到SYN-SEND状态，等待服务器确认</p><p>2、服务器收到SYN包，必须确认客户的SYN（ack=i+1）,同时自己也发送一个SYN包（SYN=k）,即SYN+ACK包，此时服务器进入SYN-RECV状态</p><p>3、客户端收到服务器的SYN+ACK包，向服务器发送确认报ACK（ack=k+1）,此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手，客户端与服务器开始传送数据。</p><h3 id="SYN攻击"><a href="#SYN攻击" class="headerlink" title="SYN攻击"></a>SYN攻击</h3><p>在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：</p><pre><code>netstat -nap | grep SYN_RECV</code></pre><h3 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h3><p>所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示：<br>TCP四次挥手.png</p><p>由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。</p><p>（1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。</p><p>（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。</p><p>（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。</p><p>（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。</p><h3 id="为什么建立连接是三次握手，而关闭连接却是四次挥手呢？"><a href="#为什么建立连接是三次握手，而关闭连接却是四次挥手呢？" class="headerlink" title="为什么建立连接是三次握手，而关闭连接却是四次挥手呢？"></a>为什么建立连接是三次握手，而关闭连接却是四次挥手呢？</h3><p>这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。</p><p>参考：<a href="https://www.jianshu.com/p/ef892323e68f" target="_blank" rel="external">https://www.jianshu.com/p/ef892323e68f</a><br><a href="https://www.cnblogs.com/yueminghai/p/6646043.html" target="_blank" rel="external">https://www.cnblogs.com/yueminghai/p/6646043.html</a></p><h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><blockquote><p>用户数据报协议(User Datagram Protocol)</p></blockquote><p>UDP是无连接的用户数据报协议。<br>所谓的无连接就是在传输数据之前不需要交换信息，没有握手建立连接的过程，只需要直接将对应的数据发送到指定的地址和端口就行。<br>故UDP的特点是不稳定，速度快，可广播，一般数据包限定64KB之内，先发未必先至。</p><h2 id="ftp-（文件传输协议）"><a href="#ftp-（文件传输协议）" class="headerlink" title="ftp （文件传输协议）"></a>ftp （文件传输协议）</h2><blockquote><p>文件传输协议(File Transfer Protocol)<br>ftp用于Internet上的控制文件的双向传输。同时，它也是一个应用程序（Application）。基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。在FTP的使用当中，用户经常遇到两个概念：”下载”（Download）和”上传”（Upload）。”下载”文件就是从远程主机拷贝文件至自己的计算机上；”上传”文件就是将文件从自己的计算机中拷贝至远程主机上。用Internet语言来说，用户可通过客户机程序向（从）远程主机上传（下载）文件。</p></blockquote><h2 id="ip和tcp"><a href="#ip和tcp" class="headerlink" title="ip和tcp"></a>ip和tcp</h2><p>TCP/IP 意味着 TCP 和 IP 在一起协同工作。</p><p>TCP 负责应用软件（比如你的浏览器）和网络软件之间的通信。</p><p>IP 负责计算机之间的通信。</p><p>TCP 负责将数据分割并装入 IP 包，然后在它们到达的时候重新组合它们。</p><p>IP 负责将包发送至接受者。</p><h2 id="tcp和udp"><a href="#tcp和udp" class="headerlink" title="tcp和udp"></a>tcp和udp</h2><h2 id="TCP与UDP基本区别"><a href="#TCP与UDP基本区别" class="headerlink" title="TCP与UDP基本区别"></a>TCP与UDP基本区别</h2><pre><code>1.基于连接与无连接2.TCP要求系统资源较多，UDP较少； 3.UDP程序结构较简单 4.流模式（TCP）与数据报模式(UDP); 5.TCP保证数据正确性，UDP可能丢包 6.TCP保证数据顺序，UDP不保证 </code></pre><p>　　<br>UDP应用场景</p><pre><code>1.面向数据报方式2.网络数据大多为短消息 3.拥有大量Client4.对数据安全性无特殊要求5.网络负担非常重，但对响应速度要求高</code></pre><p>具体编程时的区别</p><pre><code>1.socket()的参数不同 2.UDP Server不需要调用listen和accept 3.UDP收发数据用sendto/recvfrom函数 4.TCP：地址信息在connect/accept时确定 5.UDP：在sendto/recvfrom函数中每次均 需指定地址信息 6.UDP：shutdown函数无效</code></pre><p>通常我们在说到网络编程时默认是指TCP编程，即用前面提到的socket函数创建一个socket用于TCP通讯，函数参数我们通常填为SOCK_STREAM。即socket(PF_INET, SOCK_STREAM, 0)，这表示建立一个socket用于流式网络通讯。</p><p>SOCK_STREAM这种的特点是面向连接的，即每次收发数据之前必须通过connect建立连接，也是双向的，即任何一方都可以收发数据，协议本身提供了一些保障机制保证它是可靠的、有序的，即每个包按照发送的顺序到达接收方。</p><p>SOCK_DGRAM这种是User Datagram Protocol协议的网络通讯，它是无连接的，不可靠的，因为通讯双方发送数据后不知道对方是否已经收到数据，是否正常收到数据。任何一方建立一个socket以后就可以用sendto发送数据，也可以用recvfrom接收数据。根本不关心对方是否存在，是否发送了数据。它的特点是通讯速度比较快。大家都知道TCP是要经过三次握手的，而UDP没有。 </p><p>基于上述不同，UDP和TCP编程步骤也有些不同，如下：</p><h3 id="TCP-1"><a href="#TCP-1" class="headerlink" title="TCP"></a>TCP</h3><p>TCP编程的服务器端一般步骤</p><pre><code>　　1、创建一个socket，用函数socket()； 　　2、设置socket属性，用函数setsockopt(); * 可选 　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 　　4、开启监听，用函数listen()； 　　5、接收客户端上来的连接，用函数accept()； 　　6、收发数据，用函数send()和recv()，或者read()和write(); 　　7、关闭网络连接； 　　8、关闭监听； </code></pre><p>TCP编程的客户端一般步骤</p><pre><code>　　1、创建一个socket，用函数socket()； 　　2、设置socket属性，用函数setsockopt();* 可选 　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 　　4、设置要连接的对方的IP地址和端口等属性； 　　5、连接服务器，用函数connect()； 　　6、收发数据，用函数send()和recv()，或者read()和write(); 　　7、关闭网络连接；</code></pre><h3 id="UDP-1"><a href="#UDP-1" class="headerlink" title="UDP"></a>UDP</h3><p>UDP编程的服务器端一般步骤 </p><pre><code>　　1、创建一个socket，用函数socket()； 　　2、设置socket属性，用函数setsockopt();* 可选 　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 　　4、循环接收数据，用函数recvfrom(); 　　5、关闭网络连接； </code></pre><p>UDP编程的客户端一般步骤 </p><pre><code>　　1、创建一个socket，用函数socket()； 　　2、设置socket属性，用函数setsockopt();* 可选 　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 　　4、设置对方的IP地址和端口等属性; 　　5、发送数据，用函数sendto(); 　　6、关闭网络连接；</code></pre><p>TCP和UDP是OSI模型中的运输层中的协议。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。</p><h3 id="UDP补充"><a href="#UDP补充" class="headerlink" title="UDP补充"></a>UDP补充</h3><p>UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中如果出现了丢包，UDO也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交给由采用UDO的应用程序去处理。换句话说，UDP将部分控制转移到应用程序去处理，自己却只提供作为传输层协议的最基本功能。UDP有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。</p><h3 id="TCP补充"><a href="#TCP补充" class="headerlink" title="TCP补充"></a>TCP补充</h3><p>TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在UDP中都没有。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。</p><h3 id="TCP与UDP区别总结"><a href="#TCP与UDP区别总结" class="headerlink" title="TCP与UDP区别总结"></a>TCP与UDP区别总结</h3><p>1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接<br>2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保   证可靠交付<br>3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的<br>  UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）<br>4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信<br>5、TCP首部开销20字节;UDP的首部开销小，只有8个字节<br>6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道</p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><blockquote><p>超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议</p></blockquote><p>HTTP是基于TCP协议的应用，请求时需建立TCP连接，而且请求包中需要包含请求方法，URI，协议版本等信息，请求结束后断开连接，完成一次请求/响应操作。故称为短连接。</p><p>而HTTP/1.1中的keep-alive所保持的长连接则是为了优化每次HTTP请求中TCP连接三次握手的麻烦和资源开销，只建立一次TCP连接，多次的在这个通道上完成请求/响应操作。</p><p>值得一提的是，服务器无法主动给客户端推送消息。<br> HTTP全称是HyperText Transfer Protocal，即：超文本传输协议，HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。</p><h3 id="HTTPS通信原理"><a href="#HTTPS通信原理" class="headerlink" title="HTTPS通信原理"></a>HTTPS通信原理</h3><p>HTTPS（Secure Hypertext Transfer Protocol）安全超文本传输协议 它是一个安全通信通道</p><p>HTTPS是HTTP over SSL/TLS，HTTP是应用层协议，TCP是传输层协议，在应用层和传输层之间，增加了一个安全套接层SSL/TLS：</p><p>SSL (Secure Socket Layer，安全套接字层)</p><p>TLS (Transport Layer Security，传输层安全协议)</p><p>SSL使用40 位关键字作为RC4流加密算法</p><h3 id="Https的作用"><a href="#Https的作用" class="headerlink" title="Https的作用"></a>Https的作用</h3><pre><code>内容加密 建立一个信息安全通道，来保证数据传输的安全；身份认证 确认网站的真实性数据完整性 防止内容被第三方冒充或者篡改</code></pre><h3 id="Https和Http"><a href="#Https和Http" class="headerlink" title="Https和Http"></a>Https和Http</h3><pre><code>https协议需要到CA申请证书。http是超文本传输协议，信息是明文传输；https 则是具有安全性的ssl加密传输协议。http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。http默认使用80端口，https默认使用443端口</code></pre><h2 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h2><p>WebSocket也是一种协议，并且也是基于TCP协议的。具体流程是WebSocket通过HTTP先发送一个标记了 Upgrade 的请求，服务端解析后开始建立TCP连接，省去了HTTP长连接每次请求都要上传header的冗余，可以理解为WebSocket是HTTP的优化，但WebSocket不仅仅在Web应用程序上得到支持。</p><h2 id="Socket连接和TCP连接"><a href="#Socket连接和TCP连接" class="headerlink" title="Socket连接和TCP连接"></a>Socket连接和TCP连接</h2><p>其实这就是一个文字游戏而已，建立Socket连接需要至少一对Socket（套接字），而创建Socket连接可以指定不同的传输层协议，即TCP或UDP，所以当采用TCP建立连接时，该Socket连接就视为一个TCP连接。而采用UDP则是无连接的。</p><h2 id="Socket和WebSocket"><a href="#Socket和WebSocket" class="headerlink" title="Socket和WebSocket"></a>Socket和WebSocket</h2><p>这两个虽然名字差不多，但却是两个完全不同的概念，就好比Java和JavaScript一样毫无关系。Socket是一套协议封装后的接口，用于建立Socket连接，而WebSocket虽然是Html5的产物，但也不仅仅局限于浏览器的应用程序，许多语言都提供了WebSocket的支持，比如C，C++，Python等。</p><h2 id="HTTP、WebSocket与TCP的关系"><a href="#HTTP、WebSocket与TCP的关系" class="headerlink" title="HTTP、WebSocket与TCP的关系"></a>HTTP、WebSocket与TCP的关系</h2><p>HTTP通信过程属于“你推一下，我走一下”的方式，客户端不发请求则服务器永远无法发送数据给客户端，而WebSocket则在进行第一次HTTP请求之后，其他全部采用TCP通道进行双向通讯。所以，HTTP和WebSocket虽都是基于TCP协议，但是两者属于完全不同的两种通讯方式。</p><table><thead><tr><th></th><th style="text-align:center">层次</th><th style="text-align:right"></th></tr></thead><tbody><tr><td>http</td><td style="text-align:center">WebSocket</td><td style="text-align:right"></td></tr><tr><td></td><td style="text-align:center">tcp</td><td style="text-align:right"></td></tr><tr><td></td><td style="text-align:center">ip</td></tr></tbody></table><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/merray/p/7918977.html" target="_blank" rel="external">https://www.cnblogs.com/merray/p/7918977.html</a></p><p><img src="https://raw.githubusercontent.com/ma1203580780/ma1203580780.github.io/master/images/TCP-IP.gif" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="web" scheme="http://martist.cn/categories/web/"/>
    
    
      <category term="web" scheme="http://martist.cn/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>web架构优化的几个点</title>
    <link href="http://martist.cn/2018/06/18/linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%84%E7%82%B9/"/>
    <id>http://martist.cn/2018/06/18/linux性能调优/性能调优的点/</id>
    <published>2018-06-17T16:00:00.000Z</published>
    <updated>2018-07-19T10:33:17.917Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><p>举一个例子，抽奖。<br>抽奖是一个典型的高并发场景应用，平时流量不多，但遇到大促活动，流量就会暴增，今年我司的717周年庆期间的日均UV就超过百万。零点时刻一时间风起云涌，网站加载缓慢，到零点30分nginx开始报http 502错误。</p><p>此处做下笔记：</p><pre><code>wikipedia上这么解释：502 Bad GatewayThe server was acting as a gateway or proxy and received an invalid response from the upstream server.503 Service UnavailableThe server is currently unavailable (because it is overloaded or down for maintenance). Generally, this is a temporary state.504 Gateway Time-outThe server was acting as a gateway or proxy and did not receive a timely response from the upstream server.</code></pre><h2 id="502-Bad-Gateway"><a href="#502-Bad-Gateway" class="headerlink" title="502 Bad Gateway"></a>502 Bad Gateway</h2><p>fpm进程挂掉或者后端程序过长时间未返回。<br>编写一个简单的php脚本gateway.php进行测试，内容很简单 &lt;?php sleep(10);echo ‘ok;’?&gt; ，开始下面的测试：</p><p>1.启动nginx，不启动fpm，直接 curl <a href="http://localhost/gateway.php" target="_blank" rel="external">http://localhost/gateway.php</a> ，响应502 bad gateway错误且nginx的error log出现错误</p><pre><code>2017/02/10 19:08:21 [error] 216#216: *84 connect() failed (111: Connection refused) while connecting to upstream, client: 172.17.0.1, server: website80.com, request: &quot;GET /gateway.php HTTP/1.1&quot;, upstream: &quot;fastcgi://127.0.0.1:9000&quot;, host: &quot;localhost&quot;</code></pre><p>2.启动fpm，修改php-fpm.conf中request_terminate_timeout的值为5s。继续 curl <a href="http://localhost/gateway.php" target="_blank" rel="external">http://localhost/gateway.php</a> ，响应502 bad gateway。nginx和php-fpm分别报错</p><pre><code>// nginx error log2017/02/10 19:10:57 [error] 246#246: *88 recv() failed (104: Connection reset by peer) while reading response header from upstream, client: 172.17.0.1, server: website80.com, request: &quot;GET /gateway.php HTTP/1.1&quot;, upstream: &quot;fastcgi://127.0.0.1:9000&quot;, host: &quot;localhost&quot;// php-fpm error log[10-Feb-2017 19:10:57] WARNING: [pool www] child 242, script &apos;/home/website/default/gateway.php&apos; (request: &quot;GET /gateway.php&quot;) execution timed out (6.205572 sec), terminating[10-Feb-2017 19:10:57] WARNING: [pool www] child 242 exited on signal 15 (SIGTERM) after 36.692467 seconds from start</code></pre><h2 id="503-Service-Unavailable"><a href="#503-Service-Unavailable" class="headerlink" title="503 Service Unavailable"></a>503 Service Unavailable</h2><p>当遇到这个状态码的时候表示服务临时不可用，比如nginx配置了频率限制而client端又超过了配置的限制后就会收到503的响应。</p><h2 id="504-Gateway-Time-out"><a href="#504-Gateway-Time-out" class="headerlink" title="504 Gateway Time-out"></a>504 Gateway Time-out</h2><p>nginx的fastcgi模块有一个fastcgi_read_timeout配置，它表示从FastCGI server获取数据的超时时间。如果超过这个配置客户端就是收到504的响应。还以 gateway.php 举例（修改fastcgi_read_timeout的值为5s）：</p><pre><code>// nginx error log2017/02/12 14:57:26 [error] 138#138: *1113 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 172.17.0.1, server: website80.com, request: &quot;GET /gateway.php HTTP/1.1&quot;, upstream: &quot;fastcgi://127.0.0.1:9000&quot;, host: &quot;localhost&quot;</code></pre><h2 id="整体设计"><a href="#整体设计" class="headerlink" title="整体设计"></a>整体设计</h2><p>在我看来，能提高服务器应对并发的能力的方式无非两种：</p><pre><code>限流削峰：通过降低实际抵达服务器的并发量，降低服务器处理压力；性能优化：从前台到硬件，优化系统各方面性能，提高服务器处理能力。</code></pre><h3 id="服务部署层面"><a href="#服务部署层面" class="headerlink" title="服务部署层面"></a>服务部署层面</h3><pre><code>web服务器和应用服务器集群分离应用服务器集群,做负载均衡,对话共享静态资源cdn防cc访问频率限制增加服务实时监控预计高并发前适时提升带宽</code></pre><h3 id="项目层面"><a href="#项目层面" class="headerlink" title="项目层面"></a>项目层面</h3><pre><code>减少http请求使用浏览器缓存启用gzip压缩css文件放在页面最上面javascript文件最下面增加队列，异步代码分层，增加复用性禁止for循环sql操作增加缓存，热点缓存，列表缓存</code></pre><h2 id="硬件层面"><a href="#硬件层面" class="headerlink" title="硬件层面"></a>硬件层面</h2><pre><code>提高磁盘io速率，使用ssd硬盘cpu升配，增加内存</code></pre><h2 id="数据库方面"><a href="#数据库方面" class="headerlink" title="数据库方面"></a>数据库方面</h2><h3 id="逻辑允许的情况下不访问数据库"><a href="#逻辑允许的情况下不访问数据库" class="headerlink" title="逻辑允许的情况下不访问数据库"></a>逻辑允许的情况下不访问数据库</h3><pre><code>使用缓存使用页面静态化</code></pre><h3 id="必须访问就优化"><a href="#必须访问就优化" class="headerlink" title="必须访问就优化"></a>必须访问就优化</h3><pre><code>参数配置索引优化sql优化分离数据库中活跃的数据读写分离批量读取和延迟修改使用搜索引擎搜索数据库中的数据使用NoSQL和Hadoop等技术</code></pre><h2 id="高并发和高可用"><a href="#高并发和高可用" class="headerlink" title="高并发和高可用"></a>高并发和高可用</h2><pre><code>高并发</code></pre><p>即在单位时间内的并发请求数非常高，因此对网站的吞吐能力和处理能力比较高。例如12306，淘宝等。</p><pre><code>高可用</code></pre><p>即对网站的稳定性要求比较高，比如不允许停止服务，某台机器出问题后不影响网站的正常访问等。</p><p>互联网应用中，通常面临的问题是前者——高并发。</p><p>高并发又分为cpu密集型和io密集型。前者要求网站的计算能力要高，后者要求网站的吞吐能力要高。</p><h2 id="http和tcp"><a href="#http和tcp" class="headerlink" title="http和tcp"></a>http和tcp</h2><h3 id="HTTP-2-0"><a href="#HTTP-2-0" class="headerlink" title="HTTP 2.0"></a>HTTP 2.0</h3><p>HTTP 2.0标准于2015年5月以RFC 7540正式发布，Google Chrome、Mozilla Firefox、Microsoft Edge和Opera已支持HTTP 2.0，并默认启用。Internet Explorer自IE 11开始支持HTTP 2.0，目前谷歌、Facebook、Twitter 等服务器已经采用2.0协议。</p><p>2016年4月26日 nginx-1.10.0 stable 也已经提供了对 HTTP 2.0的支持，理论上不需要对程序进行优化，仅仅更换 HTTP 2.0，就可以有效的提升50%以上的性能。</p><h3 id="客户端优化"><a href="#客户端优化" class="headerlink" title="客户端优化"></a>客户端优化</h3><pre><code>重用TCP连接至关重要，频繁的三次握手是对性能极大的浪费不能让数据传输的更快，可以让数据传输的更短压缩数据，减少不必要的比特传输再快也快不不过什么也不用发，能少发就少发消除不必要的连接和数据传输本身就是很大的优化，优化好TCP是所有应用高性能的前提和基础。</code></pre><h3 id="浏览器优化"><a href="#浏览器优化" class="headerlink" title="浏览器优化"></a>浏览器优化</h3><pre><code>减少DNS查找：每一次主机名解析都需要一次网络往返，从而增加请求的延迟时间，同时还会阻塞后续请求。重用TCP连接：尽可能使用持久连接，以消除 TCP 握手和慢启动延迟（Keep-Alive减少HTTP重定向：HTTP 重定向极费时间，特别是不同域名之间的重定向，更加费时；这里面既有额外的 DNS 查询、 * TCP握手，还有其他延迟。最佳的重定向次数为零。HTTPS优化：启用TLS的会话缓存和无状态恢复及共享（可以减少HTTPS后续验证时间）去掉不必要的资源：任何请求都不如没有请求快。在客户端缓存资源：应该缓存应用资源，从而避免每次请求都发送相同的内容。浏览器提供了 Cache-Control，Last-Modified 和 ETag 首部提供验证机制，可以让不经常变更的内容直接从本地获取避免重复访问服务器拉取同样的资源，要说最快的网络请求，那就是不用发送请求就能获取资源。传输压缩过的内容：传输前应该压缩应用资源，把要传输的字节减至最少：确保对每种要传输的资源采用最好的压缩手段。 图片一般会占到一个网页需要传输的总字节数的一半，HTML、 CSS 和 JavaScript 等文本资源的大小经过 gzip 压缩平均可以减少 60%~80。打包资源减少HTTP请求：拼接资源如图片精灵技术，合并CSS，JS等文件以减少HTTP请求。合理设置资源域名：HTTP 规定为了防止客户端同时发起的请求过多给服务器造成自我DDOS，客户端对于单个域名一次最多不可发起超过6个并行请求，因此页面中同域名下资源太多，会造成等待6个资源的返而以防造成请求阻塞，可以用多个域名来突破并行请求数量。</code></pre><h2 id="借鉴"><a href="#借鉴" class="headerlink" title="借鉴"></a>借鉴</h2><p><a href="https://my.oschina.net/u/3833719/blog/1801552" target="_blank" rel="external">https://my.oschina.net/u/3833719/blog/1801552</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="linux" scheme="http://martist.cn/categories/linux/"/>
    
    
      <category term="linux" scheme="http://martist.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu性能查看</title>
    <link href="http://martist.cn/2018/06/18/linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/linux%E6%80%A7%E8%83%BD%E6%9F%A5%E7%9C%8B/"/>
    <id>http://martist.cn/2018/06/18/linux性能调优/linux性能查看/</id>
    <published>2018-06-17T16:00:00.000Z</published>
    <updated>2018-07-09T03:55:47.449Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="linux服务器性能查看"><a href="#linux服务器性能查看" class="headerlink" title="linux服务器性能查看"></a>linux服务器性能查看</h2><h3 id="cpu性能查看"><a href="#cpu性能查看" class="headerlink" title="cpu性能查看"></a>cpu性能查看</h3><p>1、查看物理cpu个数：</p><pre><code>cat /proc/cpuinfo |grep &quot;physical id&quot;|sort|uniq|wc -l</code></pre><p>2、查看每个物理cpu中的core个数：</p><pre><code>cat /proc/cpuinfo |grep &quot;cpu cores&quot;|wc -l</code></pre><p>3、逻辑cpu的个数：</p><pre><code>cat /proc/cpuinfo |grep &quot;processor&quot;|wc -l</code></pre><p>物理cpu个数*核数=逻辑cpu个数（不支持超线程技术的情况下）</p><h3 id="内存查看"><a href="#内存查看" class="headerlink" title="内存查看"></a>内存查看</h3><p>1、查看内存使用情况：</p><pre><code>#free -m            total       used       free     shared    buffers     cachedMem:          3949       2519       1430          0        189       1619-/+ buffers/cache:        710       3239Swap:         3576          0       3576</code></pre><p>解释</p><pre><code>total：内存总数used：已经使用的内存数free：空闲内存数shared：多个进程共享的内存总额- buffers/cache：(已用)的内存数，即used-buffers-cached+ buffers/cache：(可用)的内存数，即free+buffers+cachedBuffer Cache用于针对磁盘块的读写；Page Cache用于针对文件inode的读写，这些Cache能有效地缩短I/O系统调用的时间。</code></pre><p>对操作系统来说free/used是系统可用/占用的内存；<br>对应用程序来说-/+ buffers/cache是可用/占用内存,因为buffers/cache很快就会被使用。</p><p>我们工作时候应该从应用角度来看。</p><h3 id="硬盘查看"><a href="#硬盘查看" class="headerlink" title="硬盘查看"></a>硬盘查看</h3><p>1、查看硬盘及分区信息：</p><pre><code>fdisk -l</code></pre><p>2、查看文件系统的磁盘空间占用情况：</p><pre><code>df -h</code></pre><p>3、查看硬盘的I/O性能（每隔一秒显示一次，显示5次）：</p><pre><code>iostat -x 1 5</code></pre><p>iostat是含在套装systat中的,可以用yum -y install systat来安装。</p><p>常关注的参数：</p><p>如%util接近100%,说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。<br>如idle小于70%，I/O的压力就比较大了，说明读取进程中有较多的wait。</p><p>4、查看linux系统中某目录的大小：</p><pre><code>du -sh /root</code></pre><p>如发现某个分区空间接近用完，可以进入该分区的挂载点，用以下命令找出占用空间最多的文件或目录，然后按照从大到小的顺序，找出系统中占用最多空间的前10个文件或目录：</p><pre><code>du -cksh *|sort -rn|head -n 10</code></pre><h3 id="查看平均负载"><a href="#查看平均负载" class="headerlink" title="查看平均负载"></a>查看平均负载</h3><p>有时候系统响应很慢，但又找不到原因，这时就要查看平均负载了，看它是否有大量的进程在排队等待。</p><p>最简单的命令：</p><pre><code>uptime   #查看过去的1分钟、5分钟和15分钟内进程队列中的平均进程数量。</code></pre><h3 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h3><p>查看内核版本号：</p><pre><code>uname -a</code></pre><p>简化命令：</p><pre><code>uname -r</code></pre><p>查看系统是32位还是64位的：</p><pre><code>file /sbin/init</code></pre><p>查看发行版：</p><pre><code>cat /etc/issuelsb_release -a</code></pre><p>查看系统已载入的相关模块：</p><pre><code>lsmod</code></pre><p>查看pci设置：</p><p>l   spci</p><h2 id="Linux服务器性能评估"><a href="#Linux服务器性能评估" class="headerlink" title="Linux服务器性能评估"></a>Linux服务器性能评估</h2><h3 id="影响Linux服务器性能的因素"><a href="#影响Linux服务器性能的因素" class="headerlink" title="影响Linux服务器性能的因素"></a>影响Linux服务器性能的因素</h3><p>操作系统级</p><pre><code>CPU内存磁盘I/O带宽网络I/O带宽</code></pre><p>程序应用级</p><p>系统性能评估标准</p><pre><code>影响性能因素     好     坏     糟糕CPU     user% + sys%&lt; 70%     user% + sys%= 85%     user% + sys% &gt;=90%内存     Swap In（si）＝0 Swap Out（so）＝0     Per CPU with 10 page/s     More Swap In &amp; Swap Out磁盘     iowait % &lt; 20%     iowait % =35%     iowait % &gt;= 50%</code></pre><p>其中：</p><pre><code>%user：表示CPU处在用户模式下的时间百分比。%sys：表示CPU处在系统模式下的时间百分比。%iowait：表示CPU等待输入输出完成时间的百分比。swap in：即si，表示虚拟内存的页导入，即从SWAP DISK交换到RAMswap out：即so，表示虚拟内存的页导出，即从RAM交换到SWAP DISK</code></pre><h3 id="系统性能分析工具"><a href="#系统性能分析工具" class="headerlink" title="系统性能分析工具"></a>系统性能分析工具</h3><p>1.常用系统命令</p><pre><code>Vmstat、sar、iostat、netstat、free、ps、top等</code></pre><p>2.常用组合方式</p><pre><code>vmstat、sar、iostat检测是否是CPU瓶颈free、vmstat检测是否是内存瓶颈iostat检测是否是磁盘I/O瓶颈netstat检测是否是网络带宽瓶颈</code></pre><p>2.1.4 Linux性能评估与优化</p><p>系统整体性能评估（uptime命令）</p><pre><code>uptime16:38:00 up 118 days, 3:01, 5 users,load average: 1.22, 1.02, 0.91</code></pre><p>注意：</p><pre><code>load average三值大小一般不能大于系统CPU的个数。    系统有8个CPU,如load average三值长期大于8，说明CPU很繁忙，负载很高，可能会影响系统性能。但偶尔大于8，一般不会影响系统性能。如load average输出值小于CPU个数，则表示CPU有空闲时间片，比如本例中的输出，CPU是非常空闲的</code></pre><h3 id="CPU性能评估"><a href="#CPU性能评估" class="headerlink" title="CPU性能评估"></a>CPU性能评估</h3><p>1.利用vmstat命令监控系统CPU</p><p>显示系统各种资源之间相关性能简要信息，主要看CPU负载情况。</p><p>下面是vmstat命令在某个系统的输出结果：</p><pre><code>[root@node1 ~]#vmstat 2 3procs———–memory———- —swap– —–io—- –system– —–cpu——r  b swpd freebuff  cache si so bi bo incs us sy idwa st0  0 0 162240 8304 67032 0 0 13 21 1007 23 0 1 98 0 00  0 0 162240 8304 67032 0 0 1 0 1010 20 0 1 100 0 00  0 0 162240 8304 67032 0 0 1 1 1009 18 0 1 99 0 0Procsr--运行和等待cpu时间片的进程数，这个值如果长期大于系统CPU的个数，说明CPU不足，需要增加CPUb--在等待资源的进程数，比如正在等待I/O、或者内存交换等。CPUus--用户进程消耗的CPU 时间百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，就需要考虑优化程序或算法。sy--内核进程消耗的CPU时间百分比。Sy的值较高时，说明内核消耗的CPU资源很多。根据经验，us+sy的参考值为80%，如果us+sy大于 80%说明可能存在CPU资源不足。</code></pre><h3 id="利用sar命令监控系统CPU"><a href="#利用sar命令监控系统CPU" class="headerlink" title="利用sar命令监控系统CPU"></a>利用sar命令监控系统CPU</h3><p>sar对系统每方面进行单独统计，但会增加系统开销，不过开销可以评估，对系统的统计结果不会有很大影响。</p><p>下面是sar命令对某个系统的CPU统计输出：</p><pre><code>[root@webserver ~]# sar -u 3 5Linux2.6.9-42.ELsmp (webserver) 11/28/2008_i686_(8 CPU)11:41:24AM CPU %user %nice%system%iowait %steal %idle11:41:27AM all 0.88 0.00 0.29 0.00 0.00 98.8311:41:30AM all 0.13 0.00 0.17 0.21 0.00 99.5011:41:33AM all 0.04 0.00 0.04 0.00 0.00 99.9211:41:36AM all 90.08 0.00 0.13 0.16 0.00 9.6311:41:39AM all 0.38 0.00 0.17 0.04 0.00 99.41Average:all 0.34 0.00 0.16 0.05 0.00 99.45</code></pre><p>输出解释如下：</p><pre><code>%user列显示了用户进程消耗的CPU 时间百分比。%nice列显示了运行正常进程所消耗的CPU 时间百分比。%system列显示了系统进程消耗的CPU时间百分比。%iowait列显示了IO等待所占用的CPU时间百分比%steal列显示了在内存相对紧张的环境下pagein强制对不同的页面进行的steal操作 。%idle列显示了CPU处在空闲状态的时间百分比。</code></pre><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>你是否遇到过系统CPU整体利用率不高，而应用缓慢的现象？</p><pre><code>在一个多CPU的系统中，如果程序使用了单线程，会出现这么一个现象，CPU的整体使用率不高，但是系统应用却响应缓慢，这可能是由于程序使用单线程的原因，单线程只使用一个CPU，导致这个CPU占用率为100%，无法处理其它请求，而其它的CPU却闲置，这就导致了整体CPU使用率不高，而应用缓慢现象的发生。</code></pre><h3 id="内存性能评估"><a href="#内存性能评估" class="headerlink" title="内存性能评估"></a>内存性能评估</h3><p>1.利用free指令监控内存</p><p>free是监控Linux内存使用状况最常用的指令，看下面的一个输出：</p><pre><code>[root@webserver ~]# free -mtotalused freesharedbuffers cachedMem:8111 7185 926 0 243 6299-/+buffers/cache:643 7468Swap:8189 0 8189</code></pre><p>经验公式</p><pre><code>应用程序可用内存/系统物理内存&gt;70%，表示系统内存资源非常充足，不影响系统性能;应用程序可用内存/系统物理内存&lt;20%，表示系统内存资源紧缺，需要增加系统内存;20%&lt;应用程序可用内存/系统物理内存&lt;70%，表示系统内存资源基本能满足应用需求，暂时不影响系统性能</code></pre><h3 id="利用vmstat命令监控内存"><a href="#利用vmstat命令监控内存" class="headerlink" title="利用vmstat命令监控内存"></a>利用vmstat命令监控内存</h3><pre><code>[root@node1 ~]#  vmstat 2 3procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st0  0      0 136184 195420 1176596    0    0     7    27   13   11  1  0 98  0  00  0      0 135868 195420 1176628    0    0     0     0  129  286  1  0 100  0  0</code></pre><p>memory</p><pre><code>swpd--切换到内存交换区的内存数量（k为单位)。如swpd值偶尔非0，不影响系统性能free--当前空闲的物理内存数量（k为单位）buff--buffers cache的内存数量，一般对块设备的读写才需要缓冲cache--page cached的内存数量</code></pre><p>一般作为文件系统cached，频繁访问的文件都会被cached，如cache值较大，说明cached的文件数较多，如果此时IO中bi比较小，说明文件系统效率比较好。</p><p>swap</p><pre><code>si--由磁盘调入内存，也就是内存进入内存交换区的数量。so--由内存调入磁盘，也就是内存交换区进入内存的数量。si、so的值长期不为0，表示系统内存不足。需增加系统内存。</code></pre><h3 id="磁盘I-O性能评估"><a href="#磁盘I-O性能评估" class="headerlink" title="磁盘I/O性能评估"></a>磁盘I/O性能评估</h3><p>1.磁盘存储基础</p><p>频繁访问的文件或数据尽可能用内存读写代替直接磁盘I/O，效率高千倍。</p><p>将经常进行读写的文件与长期不变的文件独立出来，分别放置到不同的磁盘设备上。</p><pre><code>对于写操作频繁的数据，可以考虑使用裸设备代替文件系统。</code></pre><p>裸设备优点：</p><p>数据可直接读写，不需经过操作系统级缓存，节省内存资源，避免内存资源争用;<br>避免文件系统级维护开销，如文件系统需维护超级块、I-node等;<br>避免了操作系统cache预读功能，减少了I/O请求</p><p>使用裸设备的缺点是：</p><pre><code>数据管理、空间管理不灵活，需要很专业的人来操作。</code></pre><p>2.利用iostat评估磁盘性能</p><pre><code>[root@webserver ~]# iostat -d 2 3Linux2.6.9-42.ELsmp (webserver) 12/01/2008_i686_(8 CPU)Device:tps Blk_read/sBlk_wrtn/sBlk_readBlk_wrtnsda 1.87 2.58 114.12 6479462 286537372Device:tps Blk_read/sBlk_wrtn/sBlk_readBlk_wrtnsda0.00 0.00 0.00 0 0Device:tps Blk_read/sBlk_wrtn/sBlk_readBlk_wrtnsda1.00 0.00 12.00 0 24</code></pre><p>解释如下：</p><pre><code>Blk_read/s--每秒读取数据块数Blk_wrtn/s--每秒写入数据块数Blk_read--读取的所有块数Blk_wrtn--写入的所有块数</code></pre><p>可通过Blk_read/s和Blk_wrtn/s值对磁盘的读写性能有一个基本的了解.<br>如Blk_wrtn/s值很大，表示磁盘写操作频繁，考虑优化磁盘或程序，<br>如Blk_read/s值很大，表示磁盘直接读操作很多，可将读取的数据放入内存</p><p>规则遵循：</p><pre><code>长期的、超大的数据读写，肯定是不正常的，这种情况一定会影响系统性能。</code></pre><h3 id="利用sar评估磁盘性能"><a href="#利用sar评估磁盘性能" class="headerlink" title="利用sar评估磁盘性能"></a>利用sar评估磁盘性能</h3><p>通过“sar –d”组合，可以对系统的磁盘IO做一个基本的统计，请看下面的一个输出：</p><pre><code>[root@webserver ~]# sar -d 2 3Linux2.6.9-42.ELsmp (webserver) 11/30/2008_i686_(8 CPU)11:09:33PM DEV tps rd_sec/swr_sec/savgrq-szavgqu-sz await svctm %util11:09:35PM dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0011:09:35PM DEV tps rd_sec/swr_sec/savgrq-szavgqu-sz await svctm %util11:09:37PM dev8-0 1.00 0.00 12.00 12.00 0.00 0.00 0.00 0.0011:09:37PM DEV tps rd_sec/swr_sec/savgrq-szavgqu-sz await svctm %util11:09:39PM dev8-0 1.99 0.00 47.76 24.00 0.00 0.50 0.25 0.05Average:DEV tps rd_sec/swr_sec/savgrq-szavgqu-sz await svctm %utilAverage:dev8-0 1.00 0.00 19.97 20.00 0.00 0.33 0.17 0.02</code></pre><p>参数含义：</p><pre><code>await--平均每次设备I/O操作等待时间（毫秒）svctm--平均每次设备I/O操作的服务时间（毫秒）%util--一秒中有百分之几的时间用于I/O操作</code></pre><h3 id="对磁盘IO性能评判标准"><a href="#对磁盘IO性能评判标准" class="headerlink" title="对磁盘IO性能评判标准"></a>对磁盘IO性能评判标准</h3><p>正常svctm应小于await值，而svctm和磁盘性能有关，CPU、内存负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。</p><p>await值取决svctm和I/O队列长度以及I/O请求模式，<br>如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，<br>如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，<br>此时可以通过更换更快的硬盘来解决问题。</p><p>%util–衡量磁盘I/O重要指标，</p><pre><code>如%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷工作，该磁盘可能存在瓶颈。</code></pre><p>可优化程序或者 通过更换 更高、更快的磁盘。</p><h3 id="网络性能评估"><a href="#网络性能评估" class="headerlink" title="网络性能评估"></a>网络性能评估</h3><p>（1）通过ping命令检测网络的连通性<br>（2）通过netstat –i组合检测网络接口状况<br>（3）通过netstat –r组合检测系统的路由表信息<br>（4）通过sar –n组合显示系统的网络运行状态</p><h2 id="Linux服务器性能调优"><a href="#Linux服务器性能调优" class="headerlink" title="Linux服务器性能调优"></a>Linux服务器性能调优</h2><h3 id="为磁盘I-O调整Linux内核电梯算法"><a href="#为磁盘I-O调整Linux内核电梯算法" class="headerlink" title="为磁盘I/O调整Linux内核电梯算法"></a>为磁盘I/O调整Linux内核电梯算法</h3><p>选择文件系统后，该算法可以平衡低延迟需求，收集足够数据，有效组织对磁盘读写请求。</p><h3 id="禁用不必要的守护进程，节省内存和CPU资源"><a href="#禁用不必要的守护进程，节省内存和CPU资源" class="headerlink" title="禁用不必要的守护进程，节省内存和CPU资源"></a>禁用不必要的守护进程，节省内存和CPU资源</h3><p>许多守护进程或服务通常非必需，消耗宝贵内存和CPU时间。将服务器置于险地。<br>禁用可加快启动时间，释放内存。</p><p>减少CPU要处理的进程数</p><p>一些应被禁用的Linux守护进程，默认自动运行：</p><pre><code>序号 守护进程 描述1 Apmd 高级电源管理守护进程2 Nfslock 用于NFS文件锁定3 Isdn ISDN Moderm支持4 Autofs 在后台自动挂载文件系统(如自动挂载CD-ROM)5 Sendmail 邮件传输代理6 Xfs X Window的字体服务器3.关掉GUI4、清理不需要的模块或功能</code></pre><p>服务器软件包中太多被启动的功能或模块实际上是不需要的(如Apache中的许多功能模块)，禁用掉有助于提高系统内存可用量，腾出资源给那些真正需要的软件，让它们运行得更快。</p><h3 id="禁用控制面板"><a href="#禁用控制面板" class="headerlink" title="禁用控制面板"></a>禁用控制面板</h3><p>在Linux中，有许多流行的控制面板，如Cpanel，Plesk，Webmin和phpMyAdmin等，禁用释放出大约120MB内存，内存使用量大约下降30-40%。</p><h3 id="改善Linux-Exim服务器性能"><a href="#改善Linux-Exim服务器性能" class="headerlink" title="改善Linux Exim服务器性能"></a>改善Linux Exim服务器性能</h3><p>使用DNS缓存守护进程，可降低解析DNS记录需要的带宽和CPU时间，DNS缓存通过消除每次都从根节点开始查找DNS记录的需求，从而改善网络性能。</p><p>Djbdns是一个非常强大的DNS服务器，它具有DNS缓存功能，Djbdns比BIND DNS服务器更安全，性能更好，可以直接通过<a href="http://cr.yp.to/下载，或通过Red" target="_blank" rel="external">http://cr.yp.to/下载，或通过Red</a> Hat提供的软件包获得。</p><h3 id="使用AES256增强gpg文件加密安全"><a href="#使用AES256增强gpg文件加密安全" class="headerlink" title="使用AES256增强gpg文件加密安全"></a>使用AES256增强gpg文件加密安全</h3><p>为提高备份文件或敏感信息安全，许多Linux系统管理员都使用gpg进行加密，在使用gpg时，最好指定gpg使用AES256加密算法，AES256使用256位密钥，它是一个开放的加密算法，美国国家安全局(NSA)使用它保护绝密信息。</p><h3 id="远程备份服务安全"><a href="#远程备份服务安全" class="headerlink" title="远程备份服务安全"></a>远程备份服务安全</h3><p>安全是选择远程备份服务最重要的因素，大多数系统管理员都害怕两件事：(黑客)可以删除备份文件，不能从备份恢复系统。</p><p>为了保证备份文件100%的安全，备份服务公司提供远程备份服务器，使用scp脚本或RSYNC通过SSH传输数据，这样，没有人可以直接进入和访问远程系统，因此，也没有人可以从备份服务删除数据。在选择远程备份服务提供商时，最好从多个方面了解其服务强壮性，如果可以，可以亲自测试一下。</p><h3 id="更新默认内核参数设置"><a href="#更新默认内核参数设置" class="headerlink" title="更新默认内核参数设置"></a>更新默认内核参数设置</h3><p>为了顺利和成功运行企业应用程序，如数据库服务器，可能需要更新一些默认的内核参数设置，例如，2.4.x系列内核消息队列参数msgmni有一个默认值(例如，共享内存，或shmmax在Red Hat系统上默认只有33554432字节)，它只允许有限的数据库并发连接，下面为数据库服务器更好地运行提供了一些建议值(来自IBM DB2支持网站)：</p><pre><code>kernel.shmmax=268435456 (32位)kernel.shmmax=1073741824 (64位)kernel.msgmni=1024fs.file-max=8192kernel.sem=”250 32000 32 1024″</code></pre><h3 id="优化TCP"><a href="#优化TCP" class="headerlink" title="优化TCP"></a>优化TCP</h3><p>优化TCP协议有助于提高网络吞吐量，跨广域网的通信使用的带宽越大，延迟时间越长时，建议使用越大的TCP Linux大小，以提高数据传输速率，TCP Linux大小决定了发送主机在没有收到数据传输确认时，可以向接收主机发送多少数据。</p><h3 id="选择正确的文件系统"><a href="#选择正确的文件系统" class="headerlink" title="选择正确的文件系统"></a>选择正确的文件系统</h3><pre><code>使用ext4文件系统取代ext3</code></pre><p>● Ext4是ext3文件系统的增强版，扩展了存储限制</p><p>●具有日志功能，保证高水平的数据完整性(在非正常关闭事件中)</p><p>●非正常关闭和重启时，它不需要检查磁盘(这是一个非常耗时的动作)</p><p>●更快的写入速度，ext4日志优化了硬盘磁头动作</p><h3 id="使用noatime文件系统挂载选项"><a href="#使用noatime文件系统挂载选项" class="headerlink" title="使用noatime文件系统挂载选项"></a>使用noatime文件系统挂载选项</h3><p>在文件系统启动配置文件fstab中使用noatime选项，如果使用了外部存储，这个挂载选项可以有效改善性能。</p><h3 id="调整Linux文件描述符限制"><a href="#调整Linux文件描述符限制" class="headerlink" title="调整Linux文件描述符限制"></a>调整Linux文件描述符限制</h3><p>Linux限制了任何进程可以打开的文件描述符数量，默认限制是每进程1024，这些限制可能会阻碍基准测试客户端(如httperf和apachebench)和Web服务器本身获得最佳性能，Apache每个连接使用一个进程，因此不会受到影响，但单进程Web服务器，如Zeus是每连接使用一个文件描述符，因此很容易受默认限制的影响。</p><p>打开文件限制是一个可以用ulimit命令调整的限制，ulimit -aS命令显示当前的限制，ulimit -aH命令显示硬限制(在未调整/proc中的内核参数前，你不能增加限制)。</p><h3 id="Linux第三方应用程序性能技巧"><a href="#Linux第三方应用程序性能技巧" class="headerlink" title="Linux第三方应用程序性能技巧"></a>Linux第三方应用程序性能技巧</h3><p>对于运行在Linux上的第三方应用程序，一样有许多性能优化技巧，这些技巧可以帮助你提高Linux服务器的性能，降低运行成本。</p><h3 id="正确配置MySQL"><a href="#正确配置MySQL" class="headerlink" title="正确配置MySQL"></a>正确配置MySQL</h3><p>为了给MySQL分配更多的内存，可设置MySQL缓存大小，要是MySQL服务器实例使用了更多内存，就减少缓存大小，如果MySQL在请求增多时停滞不动，就增加MySQL缓存。</p><h3 id="正确配置Apache"><a href="#正确配置Apache" class="headerlink" title="正确配置Apache"></a>正确配置Apache</h3><p>检查Apache使用了多少内存，再调整StartServers和MinSpareServers参数，以释放更多的内存，将有助于你节省30-40%的内存。</p><h3 id="分析Linux服务器性能"><a href="#分析Linux服务器性能" class="headerlink" title="分析Linux服务器性能"></a>分析Linux服务器性能</h3><p>提高系统效率最好的办法是找出导致整体速度下降的瓶颈并解决掉，下面是找出系统关键瓶颈的一些基本技巧：</p><p>● 当大型应用程序，如OpenOffice和Firefox同时运行时，计算机可能会开始变慢，内存不足的出现几率更高。</p><p>● 如果启动时真的很慢，可能是应用程序初次启动需要较长的加载时间，一旦启动好后运行就正常了，否则很可能是硬盘太慢了。</p><p>●CPU负载持续很高，内存也够用，但CPU利用率很低，可以使用CPU负载分析工具监控负载时间。</p><h3 id="学习5个Linux性能命令"><a href="#学习5个Linux性能命令" class="headerlink" title="学习5个Linux性能命令"></a>学习5个Linux性能命令</h3><p>使用几个命令就可以管理Linux系统的性能了，下面列出了5个最常用的Linux性能命令，包括</p><pre><code>top、vmstat、iostat、free、sartop</code></pre><p>当前内核服务的任务，还显示许多主机状态的统计数据，默认情况下，它每隔5秒自动更新一次。<br>如：当前正常运行时间，系统负载，进程数量和内存使用率，</p><p>此外，这个命令也显示了那些使用最多CPU时间的进程(包括每个进程的各种信息，如运行用户，执行的命令等)。</p><pre><code>vmstat</code></pre><p>Vmstat命令提供当前CPU、IO、进程和内存使用率的快照，它和top命令类似，自动更新数据，如：</p><pre><code>$ vmstat 10iostat</code></pre><p>Iostat提供三个报告：CPU利用率、设备利用率和网络文件系统利用率，使用-c，-d和-h参数可以分别独立显示这三个报告。</p><pre><code>free</code></pre><p>显示主内存和交换空间内存统计数据，指定-t参数显示总内存，指定-b参数按字节为单位，使用-m则以兆为单位，默认情况下千字节为单位。</p><p>Free命令也可以使用-s参数加一个延迟时间(单位：秒)连续运行，如：</p><pre><code>$ free -s 5sar</code></pre><p>收集，查看和记录性能数据，这个命令比前面几个命令历史更悠久，它可以收集和显示较长周期的数据。</p><p>其它</p><p>下面是一些归类为其它的性能技巧：</p><h3 id="将日志文件转移到内存中"><a href="#将日志文件转移到内存中" class="headerlink" title="将日志文件转移到内存中"></a>将日志文件转移到内存中</h3><p>当一台机器处于运行中时，最好是将系统日志放在内存中，当系统关闭时再将其复制到硬盘，当你运行一台开启了syslog功能的笔记本电脑或移动设备时，ramlog可以帮助你提高系统电池或移动设备闪存驱动器的寿命，使用ramlog的一个好处是，不用再担心某个守护进程每隔30秒向syslog发送一条消息，放在以前，硬盘必须随时保持运转，这样对硬盘和电池都不好。</p><h3 id="先打包，后写入"><a href="#先打包，后写入" class="headerlink" title="先打包，后写入"></a>先打包，后写入</h3><p>在内存中划分出固定大小的空间保存日志文件，这意味着笔记本电脑硬盘不用一直保持运转，只有当某个守护进程需要写入日志时才运转，注意ramlog使用的内存空间大小是固定的，否则系统内存会很快被用光，如果笔记本使用固态硬盘，可以分配50-80MB内存给ramlog使用，ramlog可以减少许多写入周期，极大地提高固态硬盘的使用寿命。</p><h3 id="一般调优技巧"><a href="#一般调优技巧" class="headerlink" title="一般调优技巧"></a>一般调优技巧</h3><p>尽可能使用静态内容替代动态内容，如果你在生成天气预告，或其它每隔1小时就必须更新的数据，最好是写一个程序，每隔1小时生成一个静态的文件，而不是让用户运行一个CGI动态地生成报告。</p><p>为动态应用程序选择最快最合适的API，CGI可能最容易编程，但它会为每个请求产生一个进程，通常，这是一个成本很高，且不必要的过程，FastCGI是更好的选择，和Apache的mod_perl一样，都可以极大地提高应用程序的性能。<br>种一棵树，最好的时间是十年前，其次是现在。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/ace-lee/p/6628079.html" target="_blank" rel="external">https://www.cnblogs.com/ace-lee/p/6628079.html</a><br><a href="https://blog.csdn.net/achang21/article/details/44041535" target="_blank" rel="external">https://blog.csdn.net/achang21/article/details/44041535</a><br><a href="https://blog.csdn.net/alibert/article/details/54375344" target="_blank" rel="external">https://blog.csdn.net/alibert/article/details/54375344</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="linux" scheme="http://martist.cn/categories/linux/"/>
    
    
      <category term="linux" scheme="http://martist.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu查看系统资源占用</title>
    <link href="http://martist.cn/2018/06/18/linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/linux%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8/"/>
    <id>http://martist.cn/2018/06/18/linux性能调优/linux查看系统资源占用/</id>
    <published>2018-06-17T16:00:00.000Z</published>
    <updated>2018-07-09T03:10:00.766Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="top命令"><a href="#top命令" class="headerlink" title="top命令"></a>top命令</h2><p> top命令可以实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具。通过top命令所提供的互动式界面，用热键可以管理。</p><p>语法</p><pre><code>top(选项)</code></pre><p>选项</p><pre><code>-b：以批处理模式操作；-c：显示完整的治命令；-d：屏幕刷新间隔时间；-I：忽略失效过程；-s：保密模式；-S：累积模式；-i&lt;时间&gt;：设置间隔时间；-u&lt;用户名&gt;：指定用户名；-p&lt;进程号&gt;：指定进程；-n&lt;次数&gt;：循环显示的次数。</code></pre><p>top交互命令</p><p>在top命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了-s选项， 其中一些命令可能会被屏蔽。</p><pre><code>h：显示帮助画面，给出一些简短的命令总结说明；k：终止一个进程；i：忽略闲置和僵死进程，这是一个开关式命令；q：退出程序；r：重新安排一个进程的优先级别；S：切换到累计模式；s：改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5s；f或者F：从当前显示中添加或者删除项目；o或者O：改变显示项目的顺序；l：切换显示平均负载和启动时间信息；m：切换显示内存信息；t：切换显示进程和CPU状态信息；c：切换显示命令名称和完整命令行；M：根据驻留内存大小进行排序；P：根据CPU使用百分比大小进行排序；T：根据时间/累计时间进行排序；w：将当前设置写入~/.toprc文件中。</code></pre><p>实例</p><pre><code>top - 09:44:56 up 16 days, 21:23,  1 user,  load average: 9.59, 4.75, 1.92Tasks: 145 total,   2 running, 143 sleeping,   0 stopped,   0 zombieCpu(s): 99.8%us,  0.1%sy,  0.0%ni,  0.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%stMem:   4147888k total,  2493092k used,  1654796k free,   158188k buffersSwap:  5144568k total,       56k used,  5144512k free,  2013180k cached</code></pre><p>解释</p><pre><code>top - 09:44:56[当前系统时间],16 days[系统已经运行了16天],1 user[个用户当前登录],load average: 9.59, 4.75, 1.92[系统负载，即任务队列的平均长度]Tasks: 145 total[总进程数],2 running[正在运行的进程数],143 sleeping[睡眠的进程数],0 stopped[停止的进程数],0 zombie[冻结进程数],Cpu(s): 99.8%us[用户空间占用CPU百分比],0.1%sy[内核空间占用CPU百分比],0.0%ni[用户进程空间内改变过优先级的进程占用CPU百分比],0.2%id[空闲CPU百分比], 0.0%wa[等待输入输出的CPU时间百分比],0.0% hi — [硬中断（Hardware IRQ）占用CPU的百分比],0.0% si — [软中断（Software Interrupts）占用CPU的百分比],Mem: 4147888k total[物理内存总量],2493092k used[使用的物理内存总量],1654796k free[空闲内存总量],158188k buffers[用作内核缓存的内存量]Swap:  5144568k total[交换区总量],56k used[使用的交换区总量],5144512k free[空闲交换区总量],2013180k cached[缓冲的交换区总量],</code></pre><p>第七行以下：各进程（任务）的状态监控</p><pre><code>PID — 进程idUSER — 进程所有者PR — 进程优先级NI — nice值。负值表示高优先级，正值表示低优先级VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR — 共享内存大小，单位kbS — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU — 上次更新到现在的CPU时间占用百分比%MEM — 进程使用的物理内存百分比TIME+ — 进程使用的CPU时间总计，单位1/100秒COMMAND — 进程名称（命令名/命令行）</code></pre><p>top命令的补充</p><p>top命令是Linux上进行系统监控的首选命令，但有时候却达不到我们的要求，比如当前这台服务器，top监控有很大的局限性。这台服务器运行着websphere集群，有两个节点服务，就是【top视图 01】中的老大、老二两个java进程，top命令的监控最小单位是进程，所以看不到我关心的java线程数和客户连接数，而这两个指标是java的web服务非常重要的指标，通常我用ps和netstate两个命令来补充top的不足。</p><p>监控java线程数：</p><pre><code>ps -eLf | grep java | wc -l</code></pre><p>监控网络客户连接数：</p><pre><code>netstat -n | grep tcp | grep 侦听端口 | wc -l</code></pre><p>上面两个命令，可改动grep的参数，来达到更细致的监控要求。</p><p>在Linux系统“一切都是文件”的思想贯彻指导下，所有进程的运行状态都可以用文件来获取。系统根目录/proc中，每一个数字子目录的名字都是运行中的进程的PID，进入任一个进程目录，可通过其中文件或目录来观察进程的各项运行指标，例如task目录就是用来描述进程中线程的，因此也可以通过下面的方法获取某进程中运行中的线程数量（PID指的是进程ID）：</p><pre><code>ls /proc/PID/task | wc -l</code></pre><p>在linux中还有一个命令pmap，来输出进程内存的状况，可以用来分析线程堆栈：</p><pre><code>pmap PID</code></pre><p>大家都熟悉Linux下可以通过top命令来查看所有进程的内存，CPU等信息。除此之外，还有其他一些命令，可以得到更详细的信息，例如进程相关</p><p>cat /proc/your_PID/status  </p><p>通过top或ps -ef | grep ‘进程名’ 得到进程的PID。该命令可以提供进程状态、文件句柄数、内存使用情况等信息。<br>内存相关</p><pre><code>vmstat -s -S M  </code></pre><p>该可以查看包含内存每个项目的报告，通过-S M或-S k可以指定查看的单位，默认为kb。结合watch命令就可以看到动态变化的报告了。</p><p>也可用  </p><pre><code>cat /proc/meminfo  </code></pre><p>要看cpu的配置信息可用</p><pre><code>cat /proc/cpuinfo  </code></pre><p>它能显示诸如CPU核心数，时钟频率、CPU型号等信息。</p><p>要查看cpu波动情况的，尤其是多核机器上，可使用</p><pre><code>mpstat -P ALL 10 </code></pre><p>该命令可间隔10秒钟采样一次CPU的使用情况，每个核的情况都会显示出来，例如，每个核的idle情况等。<br>只需查看均值的，可用</p><pre><code>iostat -c </code></pre><p>IO相关</p><pre><code>iostat -P ALL  </code></pre><p>该命令可查看所有设备使用率、读写字节数等信息。</p><p>另外，htop ，有时间可以用一下。</p><h2 id="Linux查看物理CPU个数、核数、逻辑CPU个数"><a href="#Linux查看物理CPU个数、核数、逻辑CPU个数" class="headerlink" title="Linux查看物理CPU个数、核数、逻辑CPU个数"></a>Linux查看物理CPU个数、核数、逻辑CPU个数</h2><pre><code># 总核数 = 物理CPU个数 X 每颗物理CPU的核数# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l# 查看CPU信息（型号）cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c## freefree命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。</code></pre><p>语法</p><pre><code>free(选项)</code></pre><p>选项</p><pre><code>-b：以Byte为单位显示内存使用情况；-k：以KB为单位显示内存使用情况；-m：以MB为单位显示内存使用情况；-o：不显示缓冲区调节列；-s&lt;间隔秒数&gt;：持续观察内存使用状况；-t：显示内存总和列；-V：显示版本信息。</code></pre><p>实例</p><pre><code>free -m            total       used       free     shared    buffers     cachedMem:          2016       1973         42          0        163       1497-/+ buffers/cache:        312       1703Swap:         4094          0       4094</code></pre><p>第一部分Mem行解释：</p><pre><code>total：内存总数；used：已经使用的内存数；free：空闲的内存数；shared：当前已经废弃不用；buffers Buffer：缓存内存数；cached Page：缓存内存数。</code></pre><p>关系：total = used + free</p><p>第二部分(-/+ buffers/cache)解释:</p><pre><code>(-buffers/cache) used内存数：第一部分Mem行中的 used – buffers – cached(+buffers/cache) free内存数: 第一部分Mem行中的 free + buffers + cached</code></pre><p>可见-buffers/cache反映的是被程序实实在在吃掉的内存，而+buffers/cache反映的是可以挪用的内存总数。</p><p>第三部分是指交换分区。</p><h2 id="uptime"><a href="#uptime" class="headerlink" title="uptime"></a>uptime</h2><p> uptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。</p><p>语法</p><pre><code>uptime(选项)</code></pre><p>选项</p><pre><code>-V：显示指令的版本信息。</code></pre><p>实例</p><p>使用uptime命令查看系统负载：</p><pre><code>[root@LinServ-1 ~]# uptime -V    #显示uptime命令版本信息procps version 3.2.7[root@LinServ-1 ~]# uptime15:31:30 up 127 days,  3:00,  1 user,  load average: 0.00, 0.00, 0.00</code></pre><p>显示内容说明：</p><pre><code>15:31:30             //系统当前时间up 127 days,  3:00   //主机已运行时间,时间越大，说明你的机器越稳定。1 user               //用户连接数，是总连接数而不是用户数load average: 0.00, 0.00, 0.00         // 系统平均负载，统计最近1，5，15分钟的系统平均负载</code></pre><p>那么什么是系统平均负载呢？ 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。</p><p>如果每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。</p><p>如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了。</p><h2 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h2><p> iostat命令被用于监视系统输入输出设备和CPU的使用情况。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。</p><p>语法</p><pre><code>iostat(选项)(参数)</code></pre><p>选项</p><pre><code>-c：仅显示CPU使用情况；-d：仅显示设备利用率；-k：显示状态以千字节每秒为单位，而不使用块每秒；-m：显示状态以兆字节每秒为单位；-p：仅显示块设备和所有被使用的其他分区的状态；-t：显示每个报告产生时的时间；-V：显示版号并退出；-x：显示扩展状态。</code></pre><p>参数</p><pre><code>间隔时间：每次报告的间隔时间（秒）；次数：显示报告的次数。</code></pre><p>实例</p><p>用iostat -x /dev/sda1来观看磁盘I/O的详细情况：</p><pre><code>iostat -x /dev/sda1 Linux 2.6.18-164.el5xen (localhost.localdomain)2010年03月26日  avg-cpu:  %user   %nice %system %iowait %steal   %idle              0.11    0.02    0.18    0.35   0.03    99.31  Device:         tps   Blk_read/s    Blk_wrtn/s  Blk_read   Blk_wrtn  sda1                0.02          0.08       0.00          2014               4 </code></pre><p>详细说明：第二行是系统信息和监测时间，第三行和第四行显示CPU使用情况（具体内容和mpstat命令相同）。这里主要关注后面I/O输出的信息，如下所示：</p><pre><code>标示    说明Device    监测设备名称rrqm/s    每秒需要读取需求的数量wrqm/s    每秒需要写入需求的数量r/s     每秒实际读取需求的数量w/s    每秒实际写入需求的数量rsec/s    每秒读取区段的数量wsec/s    每秒写入区段的数量rkB/s    每秒实际读取的大小，单位为KBwkB/s    每秒实际写入的大小，单位为KBavgrq-sz    需求的平均大小区段avgqu-sz    需求的平均队列长度await    等待I/O平均的时间（milliseconds）svctm    I/O需求完成的平均时间%util    被I/O需求消耗的CPU百分比</code></pre><h2 id="其他相关命令"><a href="#其他相关命令" class="headerlink" title="其他相关命令"></a>其他相关命令</h2><pre><code>dstatinotifywaitsartloadiotopstracetopifstatltracenethogsfreefuserlsofuptimetimevmstatmpstat</code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://man.linuxde.net" target="_blank" rel="external">http://man.linuxde.net</a><br><a href="https://www.cnblogs.com/dragonsuc/p/5512797.html" target="_blank" rel="external">https://www.cnblogs.com/dragonsuc/p/5512797.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="linux" scheme="http://martist.cn/categories/linux/"/>
    
    
      <category term="linux" scheme="http://martist.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>electron入门</title>
    <link href="http://martist.cn/2018/06/03/Elecctron/electron%E5%85%A5%E9%97%A8/"/>
    <id>http://martist.cn/2018/06/03/Elecctron/electron入门/</id>
    <published>2018-06-02T16:00:00.000Z</published>
    <updated>2018-09-04T09:42:16.010Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><p>最近对桌面端的开发有兴趣，挑选了electron这门语言，打算着手开发一款公司现在已有产品的桌面级应用。</p><h2 id="了解electron"><a href="#了解electron" class="headerlink" title="了解electron"></a>了解electron</h2><p>为什么选择 Electron</p><pre><code>Electron提供了一个Nodejs的运行时，专注于构建桌面应用，同时使用web页面来作为应用的GUI，你可以将其看作是一个由JavaScript控制的迷你版的Chromium浏览器。</code></pre><h2 id="Electron-概述"><a href="#Electron-概述" class="headerlink" title="Electron 概述"></a>Electron 概述</h2><p>简单来说，Electron为用纯JavaScript创建桌面应用提供了运行时。原理是，Electron调用你在package.json中定义的main文件并执行它。main文件（通常被命名为main.js）会创建一个内含渲染完的web页面的应用窗口，并添加与你操作系统的原生GUI（图形界面）交互的功能。</p><p>详细地说，当用Electron启动一个应用，会创建一个主进程。这个主进程负责与你系统原生的GUI进行交互并为你的应用创建GUI（在你的应用窗口）。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/buzhiqianduan/p/7620099.html" target="_blank" rel="external">https://www.cnblogs.com/buzhiqianduan/p/7620099.html</a><br><a href="https://blog.csdn.net/smallsfe/article/details/54705675?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="external">https://blog.csdn.net/smallsfe/article/details/54705675?utm_source=itdadao&amp;utm_medium=referral</a><br><a href="https://electronjs.org/docs/tutorial/debugging-main-process" target="_blank" rel="external">https://electronjs.org/docs/tutorial/debugging-main-process</a><br><a href="https://www.cnblogs.com/dengyulinBlog/p/6141636.html" target="_blank" rel="external">https://www.cnblogs.com/dengyulinBlog/p/6141636.html</a><br><a href="https://blog.csdn.net/u014595019/article/details/53436296" target="_blank" rel="external">https://blog.csdn.net/u014595019/article/details/53436296</a><br><a href="https://www.ejiakt.com/course/18" target="_blank" rel="external">https://www.ejiakt.com/course/18</a><br><a href="https://www.jianshu.com/p/1687f8dcd70c" target="_blank" rel="external">https://www.jianshu.com/p/1687f8dcd70c</a><br><a href="https://legacy.gitbook.com/book/simulatedgreg/electron-vue/details/cn【基于" target="_blank" rel="external">https://legacy.gitbook.com/book/simulatedgreg/electron-vue/details/cn【基于</a> vue (基本上是它听起来的样子) 来构造 electron 应用程序的样板代码。】</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="electron" scheme="http://martist.cn/categories/electron/"/>
    
    
      <category term="electron" scheme="http://martist.cn/tags/electron/"/>
    
  </entry>
  
  <entry>
    <title>多列索引</title>
    <link href="http://martist.cn/2018/06/01/MYSQL/%E5%A4%9A%E5%88%97%E7%B4%A2%E5%BC%95/"/>
    <id>http://martist.cn/2018/06/01/MYSQL/多列索引/</id>
    <published>2018-05-31T16:00:00.000Z</published>
    <updated>2018-06-03T06:19:03.211Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>mysql中 myisam，innodb默认使用的是Btree索引。<br>索引那这个数据结构最后是排好序；就像新华字典他的目录就是按照a,b,c..这样排好序的；<br>所以你在找东西的时候才快，比如你找 “中” 这个字的解释，你肯定就会定位到目录的 z 开头部分；<br>组合索引可以这样理解，比如（a,b,c），abc都是排好序的，在任意一段a的下面b都是排好序的，任何一段b下面c都是排好序的；</p><h2 id="生效规则"><a href="#生效规则" class="headerlink" title="生效规则"></a>生效规则</h2><p>从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的索引没有起作用，比如</p><pre><code>where a=3 and b=45 and c=5 .... 这种三个索引顺序使用中间没有断点，全部发挥作用；where a=3 and c=5... 这种情况下b就是断点，a发挥了效果，c没有效果where b=3 and c=4... 这种情况下a就是断点，在a后面的索引都没有发挥作用，这种写法联合索引没有发挥任何效果；where b=45 and a=3 and c=5 .... 这个跟第一个一样，全部发挥作用，abc只要用上了就行，跟写的顺序无关</code></pre><p>（a,b,c） 三个列上加了联合索引（是联合索引 不是在每个列上单独加索引）</p><p>还需注意，  (a,b,c)多列索引和 (a,c,b)是不一样的，看上面的图也看得出来关系顺序是不一样的；<br>分析几个实际例子来加强理解；<br>分析句子中使用的索引情况</p><pre><code>(0)    select * from mytable where a=3 and b=5 and c=4;abc三个索引都在where条件里面用到了，而且都发挥了作用(1)    select * from mytable where  c=4 and b=6 and a=3;这条语句列出来只想说明 mysql没有那么笨，where里面的条件顺序在查询之前会被mysql自动优化，效果跟上一句一样(2)    select * from mytable where a=3 and c=7;a用到索引，b没有用，所以c是没有用到索引效果的(3)    select * from mytable where a=3 and b&gt;7 and c=3;a用到了，b也用到了，c没有用到，这个地方b是范围值，也算断点，只不过自身用到了索引(4)    select * from mytable where b=3 and c=4;因为a索引没有使用，所以这里 bc都没有用上索引效果(5)    select * from mytable where a&gt;4 and b=7 and c=9;a用到了  b没有使用，c没有使用(6)    select * from mytable where a=3 order by b;a用到了索引，b在结果排序中也用到了索引的效果，前面说了，a下面任意一段的b是排好序的(7)    select * from mytable where a=3 order by c;a用到了索引，但是这个地方c没有发挥排序效果，因为中间断点了，使用 explain 可以看到 filesort(8)    select * from mytable where b=3 order by a;b没有用到索引，排序中a也没有发挥索引效果</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="MySQL" scheme="http://martist.cn/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://martist.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Innodb 锁行还是锁表</title>
    <link href="http://martist.cn/2018/06/01/MYSQL/Innodb%20%E9%94%81%E8%A1%8C%E8%BF%98%E6%98%AF%E9%94%81%E8%A1%A8/"/>
    <id>http://martist.cn/2018/06/01/MYSQL/Innodb 锁行还是锁表/</id>
    <published>2018-05-31T16:00:00.000Z</published>
    <updated>2018-06-05T08:45:57.963Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><p>InnoDB默认行级锁。行级锁都是基于索引的。</p><p>InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！ </p><p>在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。</p><h2 id="行级锁变为表级锁情况"><a href="#行级锁变为表级锁情况" class="headerlink" title="行级锁变为表级锁情况"></a>行级锁变为表级锁情况</h2><pre><code>1、如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住。2、表字段进行变更。3、进行整表查询。(没使用索引)4、like语句查询的时候。(没使用索引)</code></pre><h2 id="行级锁与死锁"><a href="#行级锁与死锁" class="headerlink" title="行级锁与死锁"></a>行级锁与死锁</h2><p>MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。</p><p>在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。</p><p>当两个事务同时执行，一个锁住了逐渐索引在等待其他相关索引，一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。</p><p>发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。</p><p>有多种方法可以避免死锁，这里只介绍常见的三种，具体如下</p><p>1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。<br>2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；<br>3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="MySQL" scheme="http://martist.cn/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://martist.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>高并发的处理思路</title>
    <link href="http://martist.cn/2018/05/31/WEB/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%9A%84%E5%A4%84%E7%90%86%E6%80%9D%E8%B7%AF/"/>
    <id>http://martist.cn/2018/05/31/WEB/高并发的处理思路/</id>
    <published>2018-05-30T16:00:00.000Z</published>
    <updated>2018-06-06T10:53:43.056Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><p><a href="https://www.cnblogs.com/luyucheng/p/6340758.html" target="_blank" rel="external">https://www.cnblogs.com/luyucheng/p/6340758.html</a></p><p><a href="https://segmentfault.com/q/1010000003018297" target="_blank" rel="external">https://segmentfault.com/q/1010000003018297</a></p><p><a href="https://www.cnblogs.com/yuliang8/p/6803238.html" target="_blank" rel="external">https://www.cnblogs.com/yuliang8/p/6803238.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="MySQL" scheme="http://martist.cn/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://martist.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>存储引擎－－MyISAM与InnoDB</title>
    <link href="http://martist.cn/2018/05/29/MYSQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
    <id>http://martist.cn/2018/05/29/MYSQL/存储引擎/</id>
    <published>2018-05-28T16:00:00.000Z</published>
    <updated>2018-06-01T08:36:31.595Z</updated>
    
    <content type="html"><![CDATA[<p>：-} <a id="more"></a></p><p>InnoDB和MyISAM是许多人在使用MySQL时最常用的两个表类型，这两个表类型各有优劣，视具体应用而定。基本的差别为：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持以及外部键等高级数据库功能。</p><h2 id="差别"><a href="#差别" class="headerlink" title="差别"></a>差别</h2><p>　　◆1.InnoDB不支持FULLTEXT类型的索引。</p><p>　　◆2.InnoDB 中不保存表的具体行数，也就是说，执行select count(<em>) from table时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(</em>)语句包含 where条件时，两种表的操作是一样的。</p><p>　　◆3.对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。</p><p>　　◆4.DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除。</p><p>　　◆5.LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性(例如外键)的表不适用。</p><p>　　◆6.InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 </p><p>　　◆7.InnoDB表的行锁也不是绝对的，假如在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表，例如update table set num=1 where name like “%aaa%”</p><p>两种类型最主要的差别就是Innodb支持事务处理与外键和行级锁。而MyISAM不支持.所以MyISAM往往就容易被人认为只适合在小项目中使用。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>MyISAM适合：(1)做很多count 的计算；(2)插入不频繁，查询非常频繁；(3)没有事务。</p><p>InnoDB适合：(1)可靠性要求比较高，或者要求事务；(2)表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;：-}
    
    </summary>
    
      <category term="MySQL" scheme="http://martist.cn/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="http://martist.cn/tags/MySQL/"/>
    
  </entry>
  
</feed>
